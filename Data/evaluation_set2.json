[
  {
    "abstract": "Navigation is a key issue for Virtual Reality (VR) applications because it forms an integral part of the feeling of presence, which should be conveyed by VR applications. This paper presents several VR navigation modes which are useful for orientation and interaction in Virtual Environments (VEs). Due to the existence of different kinds of applications several navigation modes are required.",
    "actual_venue": "Vrcai"
  },
  {
    "abstract": "We have met many software engineering researchers who would like to evaluate a tool or system they developed with real users, but do not know how to begin. In this second iteration of the USER workshop, attendees will collaboratively design, develop, and pilot plans for conducting user evaluations of their own tools and/or software engineering research projects. Attendees will gain practical experience with various user evaluation methods through scaffolded group exercises, panel discussions, and mentoring by a panel of user-focused software engineering researchers. Together, we will establish a community of like-minded researchers and developers to help one another improve our research and practice through user evaluation.",
    "actual_venue": "Icse"
  },
  {
    "abstract": "PatchMaker is a network management tool that tracks and stores descriptions of physical network patches in a database. Physical patches are cables that connect switches, patch panels, and room ports. PatchMaker allows administrators to manage switch ports from multiple vendors giving them the ability to enable/disable ports, make VLAN changes, and perform other switch port functions through a common web front-end. Finally, PatchMaker aids in host management by tracing network connections, identifying what kinds of devices are connected to the network, and helping to troubleshoot physical network problems.",
    "actual_venue": "Lisa"
  },
  {
    "abstract": "This work derives a family of dilation matrices for the body-centered cubic (BCC) lattice, which is optimal in the sense of spectral sphere packing. While satisfying the necessary conditions for dilation, these matrices are all cube roots of an integer scalar matrix. This property offers theoretical advantages for construction of wavelet functions in addition to the practical advantages when itera...",
    "actual_venue": "Ieee Signal Processing Letters"
  },
  {
    "abstract": "New methodology for pattern recognition is presented which is based on design of invariant reference points. It is shown that the k-NN distance classifier is a special case of this methodology. New classifiers within this framework are also described.",
    "actual_venue": "Rough Sets And Current Trends In Computing"
  },
  {
    "abstract": "In this paper, we propose an aspect-oriented language, called SHL (Security Hardening Language), for specifying systematically the security hardening solutions. This language constitutes our new achievement towards developing our security hardening framework. SHL allows the description and specification of security hardening plans and patterns that are used to harden systematically security into the code. It is a minimalist language built on top of the current aspect-oriented technologies that are based on advice-poincut model and can also be used in conjunction with them. The primary contribution of this approach is providing the security architects with the capabilities to perform security hardening of software by applying well-defined solution and without the need to have expertise in the security solution domain. At the same time, the security hardening is applied in an organized and systematic way in order not to alter the original functionalities of the software. We explore the viability and relevance of our proposition by applying it into a case study and presenting the experimental results of securing the connections of open source software.",
    "actual_venue": "Secrypt : Proceedings Of The International Conference On Security And Cryptography"
  },
  {
    "abstract": "In recent years, researches on travel recommendation have attracted extensive attentions due to the wide applications. Among them, one of the active topics is constraint-based trip recommendation for meeting user's personal requirements. Although a number of studies on this topic have been proposed in literatures, most of them only regard the user-specific constraints as some filtering conditions for planning the trip. In fact, immersing the constraints into travel recommendation systems to provide a personalized trip is desired for users. Furthermore, time complexity of trip planning from a set of attractions is sensitive to the scalability of travel regions. Hence, how to reduce the computational cost by parallel cloud computing techniques is also a critical issue. In this paper, we propose a novel framework named Personalized Trip Recommendation (PTR) to efficiently recommend the personalized trips meeting multiple constraints of users by mining user's check-in behaviors. In PTR, a mining-based module is first proposed to estimate the scores of attractions by considering both of user-based preferences and temporal-based properties. Then, a trip planning algorithm named Parallel Trip-Mine+ is proposed to efficiently plan the trip that satisfies multiple user-specific constraints. To our best knowledge, this is the first work on travel recommendation that considers the issues of multiple constraints, social relationship, temporal property and parallel computing simultaneously. Through comprehensive experimental evaluations on a real check-in dataset obtained from Gowalla, PTR is shown to deliver excellent performance.",
    "actual_venue": "Sigspatial/Gis"
  },
  {
    "abstract": "This paper presents a system for image replica detection. The idea behind the proposed approach is to adapt a system for detecting the replica of a specific reference image. The system is then able to classify test images as replicas of the reference image or as unrelated images. More precisely, the test procedure is as follows. A set of features is extracted from a test image, representing texture, colour and grey-level characteristics. These features are then feed into a preprocessing step, which is fine-tuned to the reference image. Finally, the resulting features are entered to a support vector classifier that determines if the test image is a replica of the reference image. Experimental results show the effectiveness of the proposed system. Target applications include search for copyright infringement (e.g. variations of copyrighted images) and known illicit content (e.g. paedophile images known to the police).",
    "actual_venue": "Signal Processing: Image Communication"
  },
  {
    "abstract": "Predictability is an important factor for determining robot motions. This paper presents a model to generate robot motions based on reliable predictability evaluated through a dynamics learning model which self-organizes object features. The model is composed of a dynamics learning module, namely Recurrent Neural Network with Parametric Bias (RNNPB), and a hierarchical neural network as a feature extraction module. The model inputs raw object images and robot motions. Through bi-directional training of the two models, object features which describe the object motion are self-organized in the output of the hierarchical neural network, which is linked to the input of RNNPB. After training, the model searches for the robot motion with high reliable predictability of object motion. Experiments were performed with the robot's pushing motion with a variety of objects to generate sliding, falling over, bouncing, and rolling motions. For objects with single motion possibility, the robot tended to generate motions that induce the object motion. For objects with two motion possibilities, the robot evenly generated motions that induce the two object motions.",
    "actual_venue": "Iros"
  },
  {
    "abstract": "In most arithmetic systems the speed is limited by the nature of the building block which makes logic decisions and by the extent to which decisions of low order numeric significance can affect results of higher significance. In this contribution, an improved DNA representation [A. Fujiwara, K. Matsumoto, W. Chen, Procedures for logic and arithmetic operations with DNA molecules, Int. J. Found. Comput. Sci. 15 (2004) 461-474] of an integer is presented and applied in DNA arithmetic operation based on a special n-moduli set. Because of the carry-free property in residue number system, the residue representation of an integer is a way of simplifying the procedure of DNA arithmetic operation and exploiting the astounding parallelism of DNA computing. Based on the special n-moduli set the degree of parallelism in residue arithmetic operation is n.",
    "actual_venue": "Applied Mathematics And Computation"
  },
  {
    "abstract": "Athletes and coaches in most professional sports make use of high-tech equipment to analyze and, subsequently, improve the athlete's performance. High-speed video cameras are employed, for instance, to record the swing of a golf club or a tennis racket, the movement of the feet while running, and the body motion in apparatus gymnastics. High-tech and high-speed equipment, however, usually implies high-cost as well. In this paper, we present a passive optical approach to capture high-speed motion using multi-exposure images obtained with low-cost commodity still cameras and a stroboscope. The recorded motion remains completely undisturbed by the motion capture process. We apply our approach to capture the motion of hand and ball for a variety of baseball pitches and present algorithms to automatically track the position, velocity, rotation axis, and spin of the ball along its trajectory. To demonstrate the validity of our setup and algorithms, we analyze the consistency of our measurements with a physically based model that predicts the trajectory of a spinning baseball. Our approach can be applied to capture a wide variety of other high-speed objects and activities such as golfing, bowling, or tennis for visualization as well as analysis purposes.",
    "actual_venue": "Acm Transactions On Graphics"
  },
  {
    "abstract": "Single nucleotide polymorphisms (SNPs) analysis is an important means to study genetic variation. A fast and cost-efficient approach to identify large numbers of novel candidates is the SNP mining of large scale sequencing projects. The increasing availability of sequence trace data in public repositories makes it feasible to evaluate SNP predictions on the DNA chromatogram level. MAVIANT, a platform-independent Multipurpose Alignment VIewing and Annotation Tool, provides DNA chromatogram and alignment views and facilitates evaluation of predictions. In addition, it supports direct manual annotation, which is immediately accessible and can be easily shared with external collaborators.Large-scale SNP mining of polymorphisms bases on porcine EST sequences yielded more than 7900 candidate SNPs in coding regions (cSNPs), which were annotated relative to the human genome. Non-synonymous SNPs were analyzed for their potential effect on the protein structure/function using the PolyPhen and SIFT prediction programs. Predicted SNPs and annotations are stored in a web-based database. Using MAVIANT SNPs can visually be verified based on the DNA sequencing traces. A subset of candidate SNPs was selected for experimental validation by resequencing and genotyping. This study provides a web-based DNA chromatogram and contig browser that facilitates the evaluation and selection of candidate SNPs, which can be applied as genetic markers for genome wide genetic studies.The stand-alone version of MAVIANT program for local use is freely available under GPL license terms at http://snp.agrsci.dk/maviant.Supplementary data are available at Bioinformatics online.",
    "actual_venue": "Ismb/Eccb (Supplement Of Bioinformatics"
  },
  {
    "abstract": "This paper presents a hash and a canonicalization algorithm for Notation 3 (N3) and Resource Description Framework (RDF) graphs. The hash algorithm produces, given a graph, a hash value such that the same value would be obtained from any other equivalent graph. Contrary to previous related work, it is well-suited for graphs with blank nodes, variables and subgraphs. The canonicalization algorithm outputs a canonical serialization of a given graph (i.e. a canonical representative of the set of all the graphs that are equivalent to it). Potential applications of these algorithms include, among others, checking graphs for identity, computing differences between graphs and graph synchronization. The former could be especially useful for crawlers that gather RDF/N3 data from the Web, to avoid processing several times graphs that are equivalent. Both algorithms have been evaluated on a big dataset, with more than 29 million triples and several millions of subgraphs and variables.",
    "actual_venue": "J Comput Syst Sci"
  },
  {
    "abstract": "Among various feature extraction algorithms, those based on genetic algorithms are promising owing to their potential parallelizability and possible applications in large scale and high dimensional data classification. However, existing genetic algorithm based feature extraction algorithms are either limited in searching optimal projection basis vectors or costly in both time and space complexities and thus not directly applicable to high dimensional data. In this paper, a direct evolutionary feature extraction algorithm is proposed for classifying high-dimensional data. It constructs projection basis vectors using the linear combination of the basis of the search space and the technique of orthogonal complement. It also constrains the search space when seeking for the optimal projection basis vectors. It evaluates individuals according to the classification performance on a subset of the training samples and the generalization ability Df the projection basis vectors represented by the individuals. We compared the proposed algorithm with some representative feature extraction algorithms in face recognition, including the evolutionary pursuit algorithm, Eigenfaces, and Fisherfaces. The results on the widely-used Yale and ORL face databases show that the proposed algorithm has an excellent performance in classification while reducing the space complexity by an order of magnitude.",
    "actual_venue": "Aaai"
  },
  {
    "abstract": "Pencil-curve machining, which is a single-pass ball-endmilling along a concave edge on a die surface, is widely employed in die-surface machining. The cutter-path used for pencil-curve machining, which is the trajectory of the “ball-center point” of a ball-endmill sliding along a concave-edge region on the die surface, is called pencil-curve. Presented in the paper is a pencil-curve tracing algorithm in which “concave-type” sharp edges are computed from a “virtually digitized” model of the tool-envelope surface. The resulting “initial” pencil-curves are then refined by applying a series of fairing operations. Illustrative examples and methods for enhancing accuracy are also presented. The proposed pencil-curve tracing algorithm has been successfully implemented in a commercial CAM system specialized in die-machining and in the CAD/CAM system CATIA®",
    "actual_venue": "SSM"
  },
  {
    "abstract": "Hub networks play an important role in many transportation and telecommunications systems. This paper introduces a new model called the hub arc location model. Rather than locate discrete hub facilities, this model locates hub arcs, which have reduced unit flow costs. Four special cases of the general hub arc location model are examined in detail. We provide motivation for the new models, and present examples and optimal solutions, using data for U.S. air passenger traffic. Results are used to compare optimal costs, hub locations, and hub arc locations with corresponding hub median optimal solutions. The results reveal interesting spatial patterns and help identify promising cities and regions for hubs. A companion paper (Campbell et al. 2005) presents integer programming formulations and solution algorithms for the new hub arc problems. It also provides details and computation times for these solution algorithms.",
    "actual_venue": "Management Science"
  },
  {
    "abstract": "Transmit beamforming has been widely adopted for wireless systems with multiple transmit antennas. For an independent block fading channel, the Grassmannian beamformer has been shown to provide very good performance using limited amount of feedback. However, the original Grassmannian beamformer does not take the time domain correlation of the channel fading into consideration. In this work, based on a first order auto-regressive (AR1) dynamic fading model, we develop two new classes of beamforming algorithms that exploit the inter-frame correlations in the channel fading. The first algorithm is based on a predictive vector quantization (PVQ) approach, and the resulting PVQ beamformer accomplishes very good SNR performance. In addition, to simplify the implementation complexity, we also develop a successive beamforming (SBF) algorithm. The new SBF scheme uses the knowledge of the previous fading blocks to aid the beamforming codebook design of the current fading block. Through numerical simulations, we demonstrate that the proposed PVQ beamformer and successive beamformer outperform several other previously proposed beamformers at various fading scenarios.",
    "actual_venue": "Ieee International Conference On Communications"
  },
  {
    "abstract": "Networks are expected to support applications with diverse traffic characteristics and Quality of Service (QoS) requirements, such as voice, data, video and multi-media. In this environment it is important to determine whether a given QoS vector is achievable (for call admission control), and if it is, design efficient resource allocation policies that deliver it.In this paper a system of T resources (wireless channels) shared by a number of un-buffered applications is considered. Packets which are not allocated a channel within the current assignment cycle are dropped. The QoS vector is equivalently described in terms of (diverse) packet dropping probabilities (p(i)), or (diverse) packet dropping rates (d(i)). The region of achievable QoS vectors is precisely determined and easy to implement scheduling policies that deliver the achievable QoS vectors are derived. Some applications to call admission control and resource management are presented along with some numerical examples.",
    "actual_venue": "Achievable Qos And Scheduling Policies For Integrated Services Wireless Networks"
  },
  {
    "abstract": "We propose a solution for the management of multiresolution data in a mobile spatial information visualization system. This system has a client server architecture and is characterized by a slow communication link. Our solution is based on use of increments, i.e. the \"difference\" between two datasets with different levels of detail. It allows reuse of locally available data and reduces the amount of data transferred between client and server.",
    "actual_venue": "Wise Workshops"
  },
  {
    "abstract": "The benefits of experimental algorithmics and algorithm engineering need to be extended to applications in the computational sciences. In this paper, we present on one such application: the reconstruction of evolutionary histories (phylogenies) from molecular data such as DNA sequences. Our presentation is not a survey of past and current work in the area, but rather a discussion of what we see as some of the important challenges in experimental algorithmics that arise from computational phylogenetics. As motivational examples or examples of possible approaches, we briefly discuss two specific uses of algorithm engineering and of experimental algorithmics from our recent research. The first such use focused on speed: we reimplemented Sankoff and Blanchette's breakpoint analysis and obtained a 200, 000-fold speedup for serial code and 108-fold speedup on a 512-processor supercluster. We report here on the techniques used in obtaining such a speedup. The second use focused on experimentation: we conducted an extensive study of quartet-based reconstruction algorithms within a parameter-rich simulation space, using several hundred CPU-years of computation. We report here on the challenges involved in designing, conducting, and assessing such a study.",
    "actual_venue": "Experimental Algorithmics"
  },
  {
    "abstract": "Substantial efforts have been made in order to cope with disjunctions in constraint based grammar formalisms (e.g. [Kasper, 1987; Maxwell and Kaplan, 1991; Dörre and Eisele, 1990].). This paper describes the roles of disjunctions and inheritance in the use of feature structures and their formal semantics. With the notion of contexts we abstract from the graph structure of feature structures and properly define the search space of alternatives. The graph unification algorithm precomputes nogood combinations, and a specialized search procedure which we propose here uses them as a controlling factor in order to delay decisions as long as there is no logical necessity for deciding.",
    "actual_venue": "Eacl"
  },
  {
    "abstract": "This paper describes the xml definition of class algebra which is available at http://xbean.cs.ccu.edu.tw/~dan/classAlgebra.xml . A sample user-defined ontology document and instance document are available at http://xbean.cs.ccu.edu.tw/~dan/userOntology.xml and http://xbean.cs.ccu.edu.tw/~dan/userInstances.xml . The class algebra ontology is very similar to the OWL ontology, but it uses its own definition of pointers for non-partOf relations. This simplifies the underlying theory as well as the syntax. The same syntax is used to define the ontology (i.e. the schema) as well as instance documents. The class algebra ontology has sufficient information to enable conversion between class algebra instance documents, SQL tables, and Java persistent objects, all of which can be queried by class algebra queries and updated by class algebra assignment operators, RMI calls, or SOAP method calls. The state-space graph of all possible orderings of class algebra operators is searchable by efficient constraint-based search techniques. Operators include guarded class algebra assignments as well as traditional SOAP or RMI method calls.",
    "actual_venue": "Web Intelligence"
  },
  {
    "abstract": "The paper presents a novel approach to automate the Change Detection (CD) problem for the specific task of road extraction. Manual approaches to CD fail in terms of the time for releasing updated maps; in the contrary, automatic approaches, based on machine learning and image processing techniques, allow to update large areas in a short time with an accuracy and precision comparable to those obtained by human operators. This work is focused on the road-graph update starting from aerial, multi-spectral data. Geore ferenced, ground data, acquired by a GPS and an inertial sensor, are integrated with aerial data to speed up the change detector. After roads extraction by means of a binary AdaBoost classifier, the old road-graph is updated exploiting a particle filter. In particular this filter results very useful to link (track) parts of roads not extracted by the classifier due to the presence of occlusions (e.g., shadows, trees).",
    "actual_venue": "Icpr"
  },
  {
    "abstract": "Most low-power PC designs were either focused on power efficiency improvement or software power management in the working states until now. Our research aims to reduce the standby power in the off state. To reduce it by redesigning the power circuit, we cut off the power supply for the unnecessary chips, except that power which is necessary for the chip needed to wake up the system. We also turn off the power supply of the power controller chip which is used to control the system power status, and we use another low-power chip instead. We redesign the power sequence of the system, to maintain the system power state while the system power state controller is turned off. Finally, we use a low-power chip to control the power supply separately by means of the remote wake up devices.",
    "actual_venue": "Ccece"
  },
  {
    "abstract": "How might we determine in practice whether 23/67 equals 33/97? Is there a quick alternative to cross-multiplying? How about reducing? Cross-multiplying checks equality of products, whereas reducing is about the opposite, factoring and cancelling. Do these very different approaches to equality of fractions always reach the same conclusion? In fact, they wouldn't, but for a critical prime-free property of the natural numbers more basic than, but essentially equivalent to, uniqueness of prime factorization. This property has ancient, though very recently upturned, origins, and was key to number theory even through Euler's work. We contrast three prime-free arguments for the property, which remedy a method of Euclid, use similarities of circles, or follow a clever proof in the style of Euclid, as in Barry Mazur's essay [22].",
    "actual_venue": "American Mathematical Monthly"
  },
  {
    "abstract": "In this paper reference models for visualization systems that have appeared in the literature are surveyed and a new reference model for distributed cooperative visualization developed in the MANICORAL project (funded by the EU Telematics Programme) is described. The relationship of earlier models to the new model is discussed. A number of cooperative visualization systems that have been reported in the literature are compared in the framework of the MANICORAL model.",
    "actual_venue": "Computer Graphics Forum"
  },
  {
    "abstract": "There are benefits, costs and significant potential risks for maintaining reliable corporate data, and many organisations do not display the appropriate attitude about ensuring high-quality data; faculty assuming that accepting data errors as a cost of doing business. This present study documents two large NE Ohio businesses, one driven by goods and the other by services. The practitioner's success of the businesses hinges on quality driven in product accuracy, data management, and service levels. Further, the support for these efforts comes from the top of the organisation, by investing the capital and labour necessary to run the business; as a result, both companies excel and thrive in their respective niches.",
    "actual_venue": "Ijbis"
  },
  {
    "abstract": "Large scale loosely coupled PCs can organize a cluster and form the grid computing on sharing each processing power; power of PCs, code migration and transaction distribution characterize the performance of distributed systems. This paper describes object code migration control mechanism in large scale loosely coupled distributed systems. The prototype of the middleware which migrates object code for computing is implemented, and the tradeoff of code migration was observed. Based on these experiments, several simulations for large scale loosely coupled PC clusters were performed, and the methodology to control code migration to have stable response time in the system is derived. The mechanism for object code migration is proposed based on the results of the simulations. The result will be applied to design the grid computing systems and mobile systems to maintain the proper performance.",
    "actual_venue": "Mobility Conference"
  },
  {
    "abstract": "The proliferation of electronic document formats impedes the dissemination and management of documents. Indeed, a common format with structural information is required to obtain document indexing and navigation. While in some formats it is easy to decode and preserve the document structure information, often the only easily obtainable representation is Postscript, where only the geometrical information remains. Even if an organization is willing to convert all its document producing activities to a structure preserving format such as HTML, the existing documents need to be converted. The paper addresses the difficult problem of extracting the structure of a document from a geometrical representation. An interactive tool to extract the document content and structure from a geometric representation (Postscript) has been developed. It successfully analyzes several documents produced with different tools, and produces structural information using the HyperText Markup Language (HTML). The end user, when presented with the extracted document structure, can interactively modify it, if needed. The tool is easily extended to recognize new constructs and is aimed at organizations needing to convert numerous documents for searching and browsing on intranets or on the Internet.",
    "actual_venue": "Icdar"
  },
  {
    "abstract": "In this paper we describe an architecture that supports the secure operation of Location Based Services (LBSs) over the Internet. In particular, we describe a three-party protocol that is used to mutually identify and authenticate users, LBSs, and a trusted middleware infrastructure that is responsible for managing the users' identity and location information. This authentication protocol is based upon the X.509 two-way authentication protocol and a mediated identity based cryptography system, and it enables users to identify and authenticate themselves to the infrastructure using their real identities. In order to preserve the users' privacy, they can identify and authenticate themselves to the LBSs using pseudonyms. This protocol can be subsequently used to exchange messages containing location information, and the confidentiality, integrity, and non-repudiation of these messages can be demonstrated.",
    "actual_venue": "Icps"
  },
  {
    "abstract": "This paper presents an adaptive controller design method for a class of system with modeling uncertainties or environment disturbance. The controller has a paralleled structure of Dynamic Matrix Control and PID Control. The weight for each of the controller can be adaptively tuned through iteratively learning. It can make full use of the model information, meanwhile resisting disturbance and overcoming the un-modeled uncertainties in a certain degree. The simulation and comparison with other control method show that this method has better tracking performance, disturbance resistance, robustness and great feasibility to be implemented in engineering application.",
    "actual_venue": "Isda"
  },
  {
    "abstract": "Decision procedures for decidable logics and logical theories have proven to be useful tools in verification. This paper describes the CVC (\"Cooperating Validity Checker\") decision procedure. CVC implements a framework for combining subsidiary decision procedures for certain logical theories into a decision procedure for the theories' union. Subsidiary decision procedures for theories of arrays, inductive datatypes, and linear real arithmetic are currently implemented. Other notable features of CVC are the incorporation of the high-performance Chaff solver for propositional reasoning, and the ability to produce independently checkable proofs for valid formulas.",
    "actual_venue": "CAV"
  },
  {
    "abstract": "We propose a novel algorithm, RankDE, to build an ensemble using an extra artificial dataset. RankDE aims at improving the overall ranking performance, which is crucial in many machine learning applications. This algorithm constructs artificial datasets that are diverse with the current training dataset in terms of ranking. We conduct experiments with real-world data sets to compare RankDE with some traditional and state-of-the-art ensembling algorithms of Bagging, Adaboost, DECORATE and Rankboost in terms of ranking. The experiments show that RankDE outperforms Bagging, DECORATE, Adaboost, and Rankboost when limited data is available. When enough training data is available, it is competitive with DECORATE and Adaboost.",
    "actual_venue": "Icdm"
  },
  {
    "abstract": "In this work we present an experimental evidence of a current dependence of the defect generation probability driving to breakdown. Based on this observation we explain the power law dependence of the charge and the time to breakdown and show its limit on pmos inversion.",
    "actual_venue": "Microelectronics Reliability"
  },
  {
    "abstract": "In the context of multicore programming, pipeline parallelism is a solution to easily transform a sequential program into a parallel one without requiring a whole rewriting of the code. The OpenMP stream-computing extension presented by Pop and Cohen proposes an extension of OpenMP to handle pipeline parallelism. However, their communication algorithm relies on Multiple-producer-Multiple-Consumer queues, while pipelined applications mostly deal with linear chains of communication, i.e., with only a single producer and a single consumer. To improve the performance of the OpenMP stream-extension, we propose to add a more specialized Single-Producer-Single-Consumer communication algorithm called Batch Queue and to select it for one-to-one communication. Our evaluation shows that Batch Queue is then able to improve the throughput up to a factor 2 on an 8-core machine both for example application and real applications. Our study shows therefore that using specialized and efficient communication algorithms can have a significant impact on the overall performance of pipelined applications.",
    "actual_venue": "Icpads"
  },
  {
    "abstract": "In this work, three variants of Ghost Solid Method (GSM) are proposed for application to the boundary conditions at the solid-solid interface of isotropic linearly elastic materials, in a Lagrangian framework. It is shown that, in the presence of the wave propagation through the solid-solid mediums, the original GSM 1] can lead to non-physical oscillations in the solution, even for first-order solvers. It is discussed and numerically shown that these oscillations will be more severe if a higher order solver is employed using the original GSM. A scheme for prediction of these non-physical oscillations at the interface is also introduced. The other two variants of GSM proposed, however, can remove the non-physical oscillations that may rise at the interface. Next, the extension to two-dimensional settings with slip and no-slip conditions at the interface is carried out. Numerous numerical examples in one- and two-dimensional settings are provided attesting to the viability and effectiveness of the GSM for treating wave propagation at the solid-solid interface.",
    "actual_venue": "J Comput Physics"
  },
  {
    "abstract": "The Movable-Boundary Integrated CBR/Bursty-data Traffic protocol MB-ICBT is a new version of hybrid protocols supporting both, circuit- and packet-switching techniques in VSAT network environments. Circuit-switching is applied to CBR traffic connections, which are admitted in the system by a conventional DAMA technique. Bursty-data traffic, on the other hand is allowed to contend in a more complex version of slotted Aloha with anticipated reservation. A movable boundary policy is applied between the two traffic compartments to adapt to network loading conditions. The introduction of the anticipated reservation access for bursty-data, together with the movable-boundary policy, serve to minimize the collision resolution delay, largely significant in VSAT networks, and increase throughput for the bursty-data traffic. The MB-ICBT protocol is analysed and tested for different bursty-data traffic models and a telephone CBR service. Simulation results are shown to indicate the enhanced performance in terms of access delay for bursty data traffic, together with an improved overall channel throughput.",
    "actual_venue": "Iscc"
  },
  {
    "abstract": "We describe a method for the automatic identification of facial features (eyes, nose, mouth and chin) and the precise localization of their fiducial points (e.g. nose tip, mouth and eye corners) in color images of face foregrounds.",
    "actual_venue": "Image And Vision Computing"
  },
  {
    "abstract": "In this paper, a 3-layer Bayesian hierarchical detection framework (BHDF) is proposed for robust parking space detection. In practice, the challenges of the parking space detection problem come from luminance variations, inter- occlusions among cars, and occlusions caused by environmental obstacles. Instead of determining the status of parking spaces one by one, the proposed BHDF framework models the inter-occluded patterns as semantic knowledge and couple local classifiers with adjacency constraints to determine the status of parking spaces in a row-by-row manner. By applying the BHDF to the parking space detection problem, the available parking spaces and the labeling of parked cars can be achieved in a robust and efficient manner. Furthermore, this BHDF framework is generic enough to be used for various kinds of detection and segmentation applications.",
    "actual_venue": "Icassp"
  },
  {
    "abstract": "The paradigmatic shift from function-oriented Web services to interactive Web services(IWSs) addresses lots of issues such as repetitious development for user interface and tiresome understanding of underlying service operations. However, the composition of existing IWSs to create value-added ones is still a prominent problem. Considering the special interactive characteristics of IWSs, current approaches to compose function-oriented services are inappropriate. This paper proposes a novel user satisfaction model to evaluate the interactive quality of a composite IWS completely. Based on the satisfaction model, an effective satisfaction-driven approach is also developed for service selection in IWSs composition, which can meet diverse interactive requirements of users.",
    "actual_venue": "Compsac"
  },
  {
    "abstract": "A potential application of BCI is the way of prosthesis control, while the traditional ways are not appropriate for those who got the high SCI (Spinal Cord Injury). In this paper, considering the practicality of BCI based prosthesis control, especially the avoidance of appended devices, the spontaneous EEG of motor imagery was used as the control signals. The motor imagery is limited in pattern variety, so in our work a careful control strategy was designed for controlling prosthesis with elbow, wrist, and hand joint. Three motor imageries including left/right hand, and feet were used in this system. One was used for switching the current controlling joint and the others were for the forward and reverse of the joints rotation. By this method, the real-time controlling of the three joints prosthesis was achieved. This paper described the auditory paradigm of motor imagery for prosthesis control at first and the relevant coefficient was used for signal analysis and recognition. Then the strategy of controlling 3 joints prosthesis was designed and finally the experiments were carried out to evaluate the ability of prosthesis controlling.",
    "actual_venue": "Case"
  },
  {
    "abstract": "Data on individuals and entities are being collected widely. These data can contain information that explicitly identifies the individual (e.g., social security number). Data can also contain other kinds of personal information (e.g., date of birth, zip code, gender) that are potentially identifying when linked with other available data sets. Data are often shared for business or legal reasons. This paper addresses the important issue of preserving the anonymity of the individuals or entities during the data dissemination process. We explore preserving the anonymity by the use of generalizations and suppressions on the potentially identifying portions of the data. We extend earlier works in this area along various dimensions. First, satisfying privacy constraints is considered in conjunction with the usage for the data being disseminated. This allows us to optimize the process of preserving privacy for the specified usage. In particular, we investigate the privacy transformation in the context of data mining applications like building classification and regression models. Second, our work improves on previous approaches by allowing more flexible generalizations for the data. Lastly, this is combined with a more thorough exploration of the solution space using the genetic algorithm framework. These extensions allow us to transform the data so that they are more useful for their intended purpose while satisfying the privacy constraints.",
    "actual_venue": "KDD"
  },
  {
    "abstract": "The explosion in the number of functional genomic datasets generated with tools such as DNA microarrays has created a critical need for resources that facilitate the interpretation of large-scale biological data. SOURCE is a web-based database that brings together information from a broad range of resources, and provides it in manner particularly useful for genome-scale analyses. SOURCE's GeneReports include aliases, chromosomal location, functional descriptions, GeneOntology annotations, gene expression data, and links to external databases. We curate published microarray gene expression datasets and allow users to rapidly identify sets of co-regulated genes across a variety of tissues and a large number of conditions using a simple and intuitive interface. SOURCE provides content both in gene and cDNA clone-centric pages, and thus simplifies analysis of datasets generated using cDNA microarrays. SOURCE is continuously updated and contains the most recent and accurate information available for human, mouse, and rat genes. By allowing dynamic linking to individual gene or clone reports, SOURCE facilitates browsing of large genomic datasets. Finally, SOURCEs batch interface allows rapid extraction of data for thousands of genes or clones at once and thus facilitates statistical analyses such as assessing the enrichment of functional attributes within clusters of genes. SOURCE is available at http://source.stanford.edu.",
    "actual_venue": "Nucleic Acids Research"
  },
  {
    "abstract": "The Hirsch citation index h is nowadays the most frequently used numerical indicator for the performance of scientists as reflected in their output and in the reaction of the scientific community reflected in citations of individual contributions. A few of the possible improvements of h are briefly reviewed. Garfield's journal impact factor (IF) characterizes the reaction of the scientific community to publications in journals, reflected in citations of all papers published in any given journal during the preceding 2 years, and normalized against all citable articles during the same period. Again, a few of the possible improvements or supplements of IF are briefly reviewed, including the journal-h index proposed by Braun, Glänzel, and Schubert. Ascribing higher weighting factors to citations of individual papers proportionally to IF is considered to be a misuse of useful numerical indices based on citations. At most, one could turn this argument on its head and one can find reasons to ascribe an inverse proportionality relative to IF for individual citations: if a paper is considered worthy to be cited even if it was published in a low-IF journal, that citation ought to be worth more than if the citation would have been from a higher-impact journal. A weight factor reflecting the prestige of the citing author(s) may also be considered.",
    "actual_venue": "Scientometrics"
  },
  {
    "abstract": "Phonotaxis is the ability to orient towards or away from sound sources. Crickets can locate conspecifics by phonotaxis to the calling (mating) song they produce, and can evade bats by negative phonotaxis from echolocation calls. The behaviour and underlying physiology have been studied in some depth, and the auditory system solves this complex problem in a unique manner.",
    "actual_venue": "Biosystems"
  },
  {
    "abstract": "In this paper we introduce a novel aspect oriented implementation language, called JAsCo. JAsCo is tailored for component based development and the Java Beans component model in particular. The JAsCo language introduces two concepts: aspect beans and connectors. An aspect bean describes behavior that interferes with the execution of a component by using a special kind of inner class, called a hook. The specification of a hook is context independent and therefore reusable. A connector on the other hand, is used for deploying one or more hooks within a specific context. To implement the JAsCo language, we propose a new \"aspect-enabled' component model, which contains build-in traps that enable to interfere with the normal execution of a component. The JAsCo component model is backward-compatible with the Java Beans component model. Furthermore, the JAsCo component model allows very flexible aspect application, adaptation and removal at run-time. The necessary tool support for the JAsCo approach has been implemented. In addition, we present a performance assessment of our current implementation.",
    "actual_venue": "Aosd"
  },
  {
    "abstract": "In the traditional new product development process, manufacturers first explore user needs and then develop responsive products. Developing an accurate understanding of a user need is not simple or fast or cheap, however. As a result, the traditional approach is coming under increasing strain as user needs change more rapidly, and as firms increasingly seek to serve \"markets of one.\"Toolkits for user innovation is an emerging alternative approach in which manufacturers actuallyabandon the attempt to understand user needs in detail in favor of transferringneed-related aspects of product and service development to users. Experience in fields where the toolkit approach has been pioneered show custom products being developed much more quickly and at a lower cost. In this paper we explore toolkits for user innovation and explain why and how they work.",
    "actual_venue": "Ssrn Electronic Journal"
  },
  {
    "abstract": "We propose a semantic paradigm for component-based specification supporting the documentation of security risk behaviour. By security risk, we mean behaviour that constitutes a risk with regard to ICT security aspects, such as confidentiality, integrity and availability. The purpose of this work is to investigate the nature of security risk in the setting of component-based system development. A better understanding of security risk at the level of components facilitates the prediction of risks related to introducing a new component into a system. The semantic paradigm provides a first step towards integrating security risk analysis into the system development process.",
    "actual_venue": "Formal Aspects In Security And Trust"
  },
  {
    "abstract": "The next generation radar systems have high performance demands on the signal processing chain. Examples include the advanced image creating sensor systems in which complex calculations are to be performed on huge sets of data in real time. Many core architectures are gaining attention as a means to overcome the computational requirements of the complex radar signal processing by exploiting massive parallelism inherent in the algorithms in an energy efficient manner. In this paper, we evaluate a many core architecture, namely a 16-core Epiphany processor, by implementing two significantly large case studies, viz. an auto focus criterion calculation and the fast factorized back-projection algorithm, both key components in modern synthetic aperture radar systems. The implementation results from the two case studies are compared on the basis of achieved performance and programmability. One of the Epiphany implementations demonstrates the usefulness of the architecture for the streaming based algorithm (the auto focus criterion calculation) by achieving a speedup of 8.9x over a sequential implementation on a state-of-the-art general-purpose processor of a later silicon technology generation and operating at a 2.7x higher clock speed. On the other case study, a highly memory-intensive algorithm (fast factorized back projection), the Epiphany architecture shows a speedup of 4.25x. For embedded signal processing, low power dissipation is equally important as computational performance. In our case studies, the Epiphany implementations of the two algorithms are, respectively, 78x and 38x more energy efficient.",
    "actual_venue": "Icpp"
  },
  {
    "abstract": "In this paper we demonstrate that parallel genetic algorithmscan profit from performing periodic centralized selectionsof distributed populations. With this combination,implementations can benefit from the variety of environmentsprovided by distributed approaches, while periodicallybeing able to consider the population as a whole anddisregard very unfit individuals. We study four differentparallel genetic algorithm implementation strategies; eachof them striking a different balance...",
    "actual_venue": "Artificial Neural Nets And Genetic Algorithms"
  },
  {
    "abstract": "Systems on chip and multicore processors emerged for the last years. The required networks on chips can be realized by multistage interconnection networks (MIN). Prior to technical realizations, establishing and investigating formal models help to choose best adequate MIN architectures. This paper presents a Petri net semantics for modeling suchMINs in case of multicast traffic. The new semantics is inspired by high-level versions of the Petri box algebra providing a method to formally represent concurrent communication systems in a fully compositional way. In our approach, a dedicated net class is formed, which leads to three kinds of basic nets describing a switching element, a packet generator, and a packet flush. With these basic nets, models of MINs of arbitrary crossbar size can be established compositionally following their inductive definition. Particular token generation within these high-level nets, as for instance, random load, yields an alternative approach to the use of stochastic Petri nets as in previous studies. The simulation of the models under step semantics provides a basis for performance evaluation and comparison of various MIN architectures and their usability for networks on chips. Particularly, multicast traffic patterns, which are important for multicore processors, can be handled by the new model.",
    "actual_venue": "Icatpn"
  },
  {
    "abstract": "An automatic, adaptive, spectrogram-based algorithm for picking the arrival time of microseismic data is proposed. The algorithm provides a significant improvement in the ratio of detected events to false triggers and in the resolution of the microseismic structure. It mainly addresses the problem of automatic picking when the signal-to-noise ratio (S/N) is low and so false and missed triggers frequently occur. It combines the short time average/long time average (STA/LTA) algorithm with an envelope algorithm. It also constructs an envelope from a time-frequency representation of the signal. The threshold is set dynamically, according to the existing noise level and the S/N ratio. The algorithm also uses the fixed LTA value to represent the noise level for a seismic record. It is applied to pick the arrival times of P-waves of local events recorded at eight stations.",
    "actual_venue": "Computers And Geosciences"
  },
  {
    "abstract": "Let $\\mathcal{P}=\\{h_1,\\dots,h_s\\}\\subset\\mathbb{Z}[Y_1,\\dots,Y_k]$, $D\\geq\\deg(h_i)$ for $1\\leq i\\leq s$, $\\sigma$ bounding the bit length of the coefficients of the $h_i$'s, and let $\\Phi$ be a quantifier-free $\\mathcal{P}$-formula defining a convex semialgebraic set. We design an algorithm returning a rational point in $\\mathcal{S}$ if and only if $\\mathcal{S}\\cap\\mathbb{Q}\\neq\\emptyset$. It requires $\\sigma^{\\mathrm{O}(1)}D^{\\mathrm{O}(k^3)}$ bit operations. If a rational point is outputted, its coordinates have bit length dominated by $\\sigma D^{\\mathrm{O}(k^3)}$. Using this result, we obtain a procedure for deciding whether a polynomial $f\\in\\mathbb{Z}[X_1,\\dots,X_n]$ is a sum of squares of polynomials in $\\mathbb{Q}[X_1,\\dots,X_n]$. Denote by $d$ the degree of $f$, $\\tau$ the maximum bit length of the coefficients in $f$, $D={n+d\\choose n}$, and $k\\leq D(D+1)-{n+2d\\choose n}$. This procedure requires $\\tau^{\\mathrm{O}(1)}D^{\\mathrm{O}(k^3)}$ bit operations, and the coefficients of the outputted polynomials have bit length dominated by $\\tau D^{\\mathrm{O}(k^3)}$.",
    "actual_venue": "Siam Journal On Optimization"
  },
  {
    "abstract": "Non rigid motion estimation is one of the main issues in several fields, ranging from medical image analysis to civil engineering.",
    "actual_venue": "Isspit"
  },
  {
    "abstract": "A numeration system based on a strictly increasing sequence of positive integers u0=1, u1u2,... expresses a non-negative integer n as a sum n=∑",
    "actual_venue": "Icalp"
  },
  {
    "abstract": "The current generation of data flow based visual programming systems is all too often limited in application. It is our contention that data flow visual languages, to be more widely accepted for solving a broad range of problems, need to be more general in their syntax, semantics, translation schemes, computational model, execution methods and scheduling. These capabilities should be accompanied by a development environment that facilitates information processing extensions needed by the user to solve a wide range of application-specific problems. This paper addresses these issues by describing and critiquing the Khoros system implemented by the University of New Mexico, Khoros Group. The Khoros infrastructure consists of several layers of interacting subsystems. A user interface development system (UIDS) combines a high-level user interface specification with methods of software development that are embedded in a code generation tool set. The UIDS is used to create, install and maintain the fundamental operators for cantata, the visual programming language component of Khoros.",
    "actual_venue": "J Vis Lang Comput"
  },
  {
    "abstract": "When we think of \"acting\" in computer games, we tend to use a lower standard than the way we think of acting in live action films or theatre. Why is acting in computer games so bad? This is an important question because we will only be able to develop compute games into a more psychologically mature narrative medium when we can imbue them with actors that audiences can believe in. In this paper we present an approach to virtual actors in games that we believe will make it easier for audiences to willingly suspend their disbelief.",
    "actual_venue": "Lecture Notes In Computer Science"
  },
  {
    "abstract": "Abstract. We propose a distributed architecture to endow multi-agent systems with a social layer in which normative positions are explicitly represented and managed,via rules. Our rules operate on a representation of the states of affairs of a multi-agent system. We define the syntax and semantics of our rules and an interpreter; we achieve greater precision and expressiveness by allowing constraints to be part of our rules. We show how the rules and states come together in a distributed architecture in which a team of administrative agents employ a tuple space to guide the execution of a multi-agent system.",
    "actual_venue": "Declarative Agent Languages And Technologies"
  },
  {
    "abstract": "The goal of this research is to provide the mobile network installed in trains faster than 300 km/h with faster than 1 Gbps IPv6 connectivity and to achieve fast handover. For faster than 1 Gbps connectivity, infrared communication devices are employed. As the network mobility protocol in IPv6, NEMO Basic Support Protocol is adopted. This paper focuses on a fast handover mechanism in the network layer. For fast handover, a cross-layer architecture called CEAL is employed. The proposed fast handover mechanism was installed on Linux. As the first step of the goal, we had a field test using a train in service of JR-West (West Japan Railway Company). The speed of the train is 120--130 km/h. The total handover time is 124.0 msec in the best case. Bi-directional video streaming was also succeeded.",
    "actual_venue": "Aintec"
  },
  {
    "abstract": "3D curvature-constrained motion planning finds applications in a wide variety of domains, including motion planning for flexible, bevel-tip medical needles, planning curvature-constrained channels in 3D printed implants for targeted brachytherapy dose delivery or channels for cooling turbine blades, and path planning for unmanned aerial vehicles (UAVs). In this work, we present a motion planning technique using sequential convex optimization for computing locally optimal, curvature-constrained trajectories to desired targets while avoiding obstacles in 3D environments. We report two main contributions in this work: (i) curvature-constrained trajectory optimization in 6D pose (position and orientation) space, and (ii) planning multiple trajectories that are mutually collision-free. We demonstrate the performance of our approach on two clinically motivated applications. Our experiments indicate that our approach can compute high-quality plans for medical needle steering in 1.6 seconds on a commodity PC, enabling re-planning during execution to correct for perturbations. Our approach can also be used for designing optimized channel layouts within 3D printed implants for intracavitary brachytherapy.",
    "actual_venue": "Icra"
  },
  {
    "abstract": "Due to its simplicity and robustness against wave-front distortion, pulse position modulation (PPM) with photon counting detector has been seriously considered for long-haul optical wireless systems. This paper evaluates the dual-pulse case and compares it with the conventional single-pulse case. Analytical expressions for symbol error rate and bit error rate are first derived and numerically evaluated, for the strong, negative-exponential turbulent atmosphere. The capacity of the turbulent FSO channel modeled as a Z-channel is evaluated, and throughput, bandwidth efficiency and energy efficiency of Dual-pulse and single-pulse PPM are subsequently assessed. It is shown that, under a set of practical constraints including pulse width and pulse repetition frequency (PRF), dual-pulse PPM enables a better channel utilization and hence a higher throughput than its single-pulse counterpart. This result is new and different from the previous idealistic studies that showed multi-pulse PPM provided no essential information-theoretic gains over single-pulse PPM.",
    "actual_venue": "Wcsp"
  },
  {
    "abstract": "The growth of the manufacturing sector is closely linked to the development of new technologies, specifically automation and robotics. However, the lack of flexibility in industrial robotics and its design oriented to large series, results in that is economically unviable for small and medium sized business due to the need for complex positioning tools and highly skilled robotic operators. Robot work cells should adapt to variations in shape and size of the parts to process. Therefore, an industrial implementation in the shipbuilding sector of a monocular CAD-based 3D localization system is shown in this paper, which adds a new step and contributes to a new concept of hyper-flexible cell, enabling robotics introduce itself in this kind of demanding market.",
    "actual_venue": "Etfa"
  },
  {
    "abstract": "In this paper, dynamic spectrum management is studied for multiple cognitive tactical radio networks coexisting in the same area. A tactical radio network is composed of a transmitter which broadcasts the same information to its multiple receivers. First, we consider the problem of power minimization subject to a minimum rate constraint and a spectral mask constraint for a single tactical radio network with multiple receivers over parallel channels (parallel multicast channels). Then, we extend the iterative waterfilling algorithm to multiple receivers for the coexistence of multiple cognitive tactical radio networks, meaning that there is no cooperation between the different networks. The power allocation is performed autonomously at the transmit side assuming knowledge of the noise variances and channel variations of the network. Simulation results show that the proposed algorithm is very robust in satisfying these constraints while minimizing the overall power in various scenarios.",
    "actual_venue": "Cognitive Radio Oriented Wireless Networks And Communications"
  },
  {
    "abstract": "This article addresses the problem of obtaining reduced complexity models of multi-reach water delivery canals that are suitable for robust and linear parameter varying (LPV) control design. In the first stage, by applying a method known from the literature, a finite dimensional rational transfer function of a priori defined order is obtained for each canal reach by linearizing the Saint-Venant equations. Then, by using block diagrams algebra, these different models are combined with linearized gate models in order to obtain the overall canal model. In what concerns the control design objectives, this approach has the advantages of providing a model with prescribed order and to quantify the high frequency uncertainty due to model approximation. A case study with a 3-reach canal is presented, and the resulting model is compared with experimental data.",
    "actual_venue": "Control Applications"
  },
  {
    "abstract": "In this paper, the bursting phenomenon in echo cancellation of telephone systems is investigated. The setup being studied here is an adaptive hybrid system with an echo canceller(EC) on the near-end and a fixed feedback on the far-end. Two effective approaches are proposed to ensure bursting does not happen. Both are based on checking the cross-correlation between the input and the error of the echo canceller. Bursting is avoided by stopping the drifting of the coefficients of the adaptive filter. The effectiveness of these two approaches is illustrated by extensive computer simulations using realistic hybrids.",
    "actual_venue": "Acoustics, Speech, and Signal Processing, 1993. ICASSP-93., 1993 IEEE International Conference  "
  },
  {
    "abstract": "The management information models currently used in the Internet have several limitations. Some of them contain errors, are missing important features, or are difficult to understand. Second, standards bodies keep reinventing the wheel, which confuses the terminology (hence customers) and wastes precious time. Third, finding a good balance between too abstract, and overly detailed models is a tough challenge, rarely achieved in practice. Last, the learning curve of existing data models is too steep. We propose to alleviate these problems by adopting a new process for designing and standardizing management information models. It is inspired by two techniques form software engineering: the iterative and incremental software development process, which addresses the shortcomings of the waterfall process usually adhered to by the IETF and DMTF; and multi-tier models, which capture different perspectives (e.g., analysis, design, and implementation) of the information model. Our main innovations are management-architecture-neutral universal information models (UIMs), sharing of conceptual models by different standard bodies, and specialization of the people involved in designing the different layers of the models. Our new process takes into account a number of constraints identified in real-life environments.",
    "actual_venue": "Communications Magazine, Ieee"
  },
  {
    "abstract": "A new approach to capacitance transient analysis, based on the matrix pencil (MP) method, is proposed for deep level transient spectroscopy (DLTS) (MP-DLTS). The MP method offers the least statistical variance of the estimates in the presence of noise. Simulation tests have shown this method to lead to a significant improvement in DLTS resolution even for low trap concentrations. Its noise sensitivity and resolution are quantified and compared with five different DLTS analysis techniques. The MP-DLTS method is found to outperform both DLTS spectrum and direct transient analysis techniques. An experimental investigation of the electrically active defects induced by a germanium preamorphization step prior to dopant implantation was undertaken using the MP-DLTS method. Two electron traps were detected in all samples and characterized",
    "actual_venue": "Instrumentation And Measurement, Ieee Transactions"
  },
  {
    "abstract": "An overview of CAPANINA, a project funded by the European Commission's 6th Framework Programme, is presented. The project is developing communications technologies for use with aerial platforms with the aim of integrating users in hard to reach areas and those disadvantaged by geography into the wider broadband network. The article discusses the three broad areas of the project. Specific aspects covered include broadband applications and services selection, along with appropriate integrated delivery configurations to deliver the required capacity and upgradeability; and the associated trials, along with the required wireless and free space optical equipment. Longer-term research underway into delivering broadband backhaul to high-speed trains from aerial platforms, enabling integration with onboard WLAN access points, is also discussed.",
    "actual_venue": "Wireless Communications, Ieee"
  },
  {
    "abstract": "Navigation of non-circular mobile robots in narrow, cluttered, partially unknown environments is considered. The paper introduces a planner capable of planning paths in these environments, while taking specific kinematic constraints and user defined optimality criteria into account. The planning is based on a graph, built and maintained in a variable, explicit configuration space representation of robot and workspace",
    "actual_venue": "Robotics And Automation Proceedings Ieee International Conference"
  },
  {
    "abstract": "The authors propose a novel method for improving the performance of ITU-T G.729A for Voice-over-IP (VoIP) applications. One of the most important features for a speech compression algorithm that is to be used for VoIP is that it be resistant to packet loss. Because of the memory that resides in the G.729A algorithm, a packet loss will not only cause degradations during the period of the loss but also following the packet loss due to the differing states of the encoder and decoder. The G.729A algorithm deals quite well with the packet loss period through error concealment, but it does not deal with the state error that follows the packet loss. The paper introduces a new scheme called recovery by reinitialization (RbR) that reduces this state error at minimal cost",
    "actual_venue": "Multimedia And Expo, Icme Ieee International Conference"
  },
  {
    "abstract": "We characterize the DMT of finite-length linear equalizers in the MIMO frequency-selective channel. We obtain the DMT in the case of cyclic-prefix transmission and provide an upper bound for the DMT in the case of zero-padding transmission. We also provide in-depth analysis for the diversity of the MMSE receiver in the fixed rate regime (i.e. zero multiplexing gain) in the cyclic-prefix transmission and obtain a lower bound on diversity. This gives better insight about the diversity of the MMSE in this regime since only upper bound exists in the literature. The MMSE diversity in this regime is function of the spectral efficiency, the data block length and the number of transmit and receive antennas.",
    "actual_venue": "Communications"
  },
  {
    "abstract": "In this paper, a new algorithm for vehicle logo recognition on the basis of an enhanced scale-invariant feature transform (SIFT)-based feature-matching scheme is proposed. This algorithm is assessed on a set of 1200 logo images that belong to ten distinctive vehicle manufacturers. A series of experiments are conducted, splitting the 1200 images to a training set and a testing set, respectively. It is shown that the enhanced matching approach proposed in this paper boosts the recognition accuracy compared with the standard SIFT-based feature-matching method. The reported results indicate a high recognition rate in vehicle logos and a fast processing time, making it suitable for real-time applications.",
    "actual_venue": "Ieee Transactions Intelligent Transportation Systems"
  },
  {
    "abstract": "Experimental studies using laboratory animal models have shown a potential vasoactive effect of natural metabolites such as glycine. The present study used intravital microscopy in laboratory rat models to study the microcirculation in the brain pial and mesentery vessels.To investigate the pial microvasculature, a stereotaxis-like animal fixing device was used. The intravital microscopy unit consisted of a binocular microscope equipped with a digital photo-video camera, processor, monitor and printer. Using reflected light, a special contact lens with an amplified focus depth provided high-resolution images of nontransparent tissue objects that typically have insufficient light exposure.Glycine had a vasodilatory effect on microvessels in the rat brain and mesenterium. The diameter of pial arterioles increased after glycine application especially markedly (up to 250% of initial size). These changes were not observed when physiological saline was used. Even a very small amount of glycine (a drop on the needle) was sufficient to stop the early stages of histamine-induced blood stasis development in 3-5 s in mesenterial microvessels.The vasodilatory effect of glycine on the pial microcirculation correlates with its reported positive therapeutic effect in cerebral ischemic stroke. The ability of glycine to avoid or prevent histamine-induced microcirculatory alterations in mesenterial microvessels may have potential clinical applications.",
    "actual_venue": "Annual International Conference Of The Ieee Engineering In Medicine And Biology Society, Vols"
  },
  {
    "abstract": "Rapid transit systems timetables are commonly designed to accommodate passenger demand in sections with the highest passenger load. However, disruptions frequently arise due to an increase in the demand, infrastructure incidences or as a consequence of fleet size reductions. All these circumstances give rise to unsupplied demand at certain stations, which generates passenger overloads in the available vehicles. The design of strategies that guarantee reasonable user waiting time with small increases of operation costs is now an important research topic. This paper proposes a tactical approach to determine optimal policies for dealing with such situations. Concretely, a short-turning strategy is analysed, where some vehicles perform short cycles in order to increase the frequency among certain stations of the lines and to equilibrate the train occupancy level. Turn-back points should be located and service offset should be determined with the objective of diminishing the passenger waiting time while preserving certain level of quality of service. Computational results and analysis for a real case study are provided.",
    "actual_venue": "Annals Of Operations Research"
  },
  {
    "abstract": "Minimizing the Euclidean distance to a set arises frequently in applications. When the set is algebraic, a measure of complexity of this optimization problem is its number of critical points. In this paper we provide a general framework to compute and count the real smooth critical points of a data matrix on an orthogonally invariant set of matrices. The technique relies on \"transfer principles\" that allow calculations to be done in the space of singular values of the matrices in the orthogonally invariant set. The calculations often simplify greatly and yield transparent formulas. We illustrate the method on several examples and compare our results to the recently introduced notion of Euclidean distance degree of an algebraic variety.",
    "actual_venue": "Siam Journal On Matrix Analysis And Applications"
  },
  {
    "abstract": "A variational model for image reconstruction is introduced and analyzed in function space. Specific to the model is the data fidelity, which is realized via a basis transformation with respect to a Riesz basis followed by interval constraints. This setting in particular covers the task of reconstructing images constrained to data obtained from JPEG or JPEG 2000 compressed files. As image prior, the total generalized variation (TGV) functional of arbitrary order is employed. The present paper, the first of two works that deal with both analytical and numerical aspects of the model, provides a comprehensive analysis in function space and defines concrete instances for particular applications. A new, noncoercive existence result and optimality conditions, including a characterization of the subdifferential of the TGV functional, are obtained in the general setting.",
    "actual_venue": "Siam Journal On Imaging Sciences"
  },
  {
    "abstract": "Image search re-ranking has proven its effectiveness in the text-based image search system. However, traditional re-ranking algorithm heavily relies on the relevance of the top-ranked images. Due to the huge semantic gap between query and the image, the text-based retrieval result is unsatisfactory. Besides, single re-ranking model has large variance and is easy to over-fit. Instead, multiple re-ranking models can better balance the biased and the variance. In this paper, we first conduct label de-noising to filter false-positive images. Then a simple greedy graph-based re-ranking algorithm is proposed to derive the resulting list. Afterwards, different images are chosen as the seed images to perform re-ranking multiple times. Using the rank fusion, the results from different graphs are combined to form a better result. Extensive experiments are conducted on the INRIA web353 dataset and demonstrate that our method achieves significant improvement over state-of-the-art methods.",
    "actual_venue": "MMM"
  },
  {
    "abstract": "Traumatic brain injury (TBI) affects over 1.5 million Americans each year, and more than 75% of TBI cases are classified as mild (mTBI). Several functional network alternations have been reported after mTBI; however, the network alterations on a large scale, particularly on connectome scale, are still unknown. To analyze brain network, in a previous work, 358 landmarks named dense individualized common connectivity based cortical landmarks (DICCCOL) were identified on cortical surface. These landmarks preserve structural connection consistency and maintain functional correspondence across subjects. Hence DICCCOLs have been shown powerful in identifying connectivity signatures in affected brains. However, on such fine scales, the longitudinal changes in brain network of mTBI patients were complicated by the noise embedded in the systems as well as the normal variability of individuals at different times. Faced with such problems, we proposed a novel framework to analyze longitudinal changes from the perspective of network clusters. Specifically, multiview spectral clustering algorithm was applied to cluster brain networks based on DICCCOLs. And both structural and functional networks were analyzed. Our results showed that significant longitudinal changes were identified from mTBI patients that can be related to the neurocognitive recovery and the brain's effort to compensate the effect of injury.",
    "actual_venue": "Lecture Notes In Computer Science"
  },
  {
    "abstract": "Editing of word-processing documents at the presentation level, with visible tracking of changes, operates at a different level of abstraction and granularity than the recorded form in common document-file formats. The consequent mismatches along with other limitations of standards for document-file formats present an anti-pattern that impedes reliable inter-product exchange of change-tracked documents. Analysis of the situation for ODF change-tracking reveals simple extensions and definitions that supplement the current specification without introducing any conflicts. Patterns of systematic testing for conformant document files, compliant processing, and verifiable interoperability are identified as essential prerequisites to dependable improvement of change-tracking in collaborative settings.",
    "actual_venue": "Dchanges@Doceng"
  },
  {
    "abstract": "In this paper we address the problem of maximizing the expected number of transplants in a kidney exchange program. We propose an integer programming model with an exponential number of decision variables which are associated with cycles. By introducing the concept of type of cycle, we avoid the complete cycle enumeration and develop a branch-and-price approach.",
    "actual_venue": "Electronic Notes In Discrete Mathematics"
  },
  {
    "abstract": "The poor performance of TCP in wireless networks is a well-known problem, and a large amount of research effort has been devoted to it. However, our own experiments show that existing solutions including split TCP and recently developed congestion control algorithms still suffer significant performance degradation in lossy environments, leaving considerable room for improvement. Rather than developing a more sophisticated congestion control algorithm, we explore a radically different approach: we instead propose to completely remove congestion control between the Wi-Fi access points and the wireless receivers. We introduce TCP Fixed, a TCP used in split TCP environments that eliminates congestion control for the last lossy hop, allowing TCP to send data as fast as the channel allows. Extensive evaluations in both lab and real-world settings demonstrate that our approach significantly improves TCP performance in the presence of packet losses. In addition, our results indicate that existing 802.11 rate adaptation schemes which strive to minimize frame loss unnecessarily decrease the data rate in the presence of TCP Fixed. These results offer new opportunities for future link-layer rate adaptation designs.",
    "actual_venue": "International Symposium On Modeling And Optimization In Mobile, Ad Hoc, And Wireless Networks"
  },
  {
    "abstract": "The paper uses EMD to construct a new transformation matrix to improve the original matrix coding algorithm and proposes a new video steganography algorithm:Improved Matrix Encoding (IME). The proposed algorithmretains the advantages of EMD and matrix encoding that it can greatly reduce the modifications of embed carrier to achieve a high embedding efficiency under the conditions of same embedding capacity. At the same time, the proposed algorithm solves the problem that the embedding rate of matrix encoding is relatively low. The experiment compared with similar algorithms show that the algorithm has advantages in PSNR, SSIM, and bitrate increase.",
    "actual_venue": "Cscloud"
  },
  {
    "abstract": "Event-based online social networks, which are used to maintain interest-based groups and to distribute and organize offline events, have recently gained increasing popularity. In event-based social networks, some groups survive and thrive, while other groups fail. How to build successful groups and what factors make a \"healthy\" group are important open problems. We address the problem of modeling social group behavior and present detailed studies on group failure prediction by analyzing a large online event-based social network. We investigate both the statistical properties and the structural features of the social groups, and find that event features play an important role in distinguishing social groups with different topics and categories. We also observe that tightly knit communities have less average event participation, and both low level diversity and high level diversity in members' event participation will harm group activity participation. We then analyze the data of thousands of social groups collected from the Meetup platform with the goal of understanding what makes a group fail. We use two different feature selection methods in this paper and build a model to predict which groups will fail over a period of time. The experimental results show that social group failures can be predicted with high accuracy, and that member features contribute significantly to the success of social groups.",
    "actual_venue": "Ieee International Conference On Big Data"
  },
  {
    "abstract": "Recent study in vision science has shown that blue light in a certain frequency band affects human circadian rhythm and impairs our health. Although applying a light blocker to an image display can block the harmful blue light, it inevitably makes an image look like an aged photo. In this paper, we show that it is possible to reduce harmful blue light while preserving the blue appearance of an image. Moreover, we optimize the spectral transmittance profile of blue light blocker based on psychophysical data and develop a color compensation algorithm to minimize color distortion. A prototype using notch filters is built as a proof of concept.",
    "actual_venue": "Acm Trans Graph"
  },
  {
    "abstract": "While several proposals for the specification and implementation of various consistency models exist, little is known about what is the consistency currently offered by online services with millions of users. Such knowledge is important, not only because it allows for setting the right expectations and justifying the behavior observed by users, but also because it can be used for improving the process of developing applications that use APIs offered by such services. To fill this gap, this paper presents a measurement study of the consistency of the APIs exported by four widely used Internet services, the Facebook Feed, Facebook Groups, Blogger, and Google+. To conduct this study, our work (1) proposes definitions for a set of relevant consistency properties, (2) develops a simple, yet generic methodology comprising a small number of tests, which probe these services from a user perspective, and try to uncover consistency anomalies that are key to our definitions, and (3) reports on the analysis of the data obtained from running these tests for a period of several weeks. Our measurement study shows that some of these services do exhibit consistency anomalies, including some behaviors that may appear counter-intuitive for users, such as the lack of session guarantees for write monotonicity.",
    "actual_venue": "Annual Ieee/Ifip International Conference On Dependable Systems And Networks"
  },
  {
    "abstract": "Wireless caching at network edges (in user devices or in base stations) is considered to be a promising solution to alleviate backhaul overload in future wireless networks. Device-to-Device (D2D)-assisted caching emerges as an attractive option. Due to the nature of D2D communications, social networks and the characteristics within are intertwined with the challenges in mobile device caching, and it has become an active area of research. In this paper, we first introduce the structure and key concepts of mobile social device caching (MSDC), elaborating the connections and differences of it to traditional caching. Furthermore, we advocate several major areas of research challenges for MSDC, such as content placement, radio resource management and routing. Moreover, a demonstration is present to illustrate the modeling of the MSDC, and performance analysis is carried out to manifest its great potentials.",
    "actual_venue": "Ieee Access"
  },
  {
    "abstract": "Over the past three decades, considerable effort has been devoted to the study of software architecture. A major portion of this effort has focused on the originally proposed view of four \"C\"s---components, connectors, configurations, and constraints---that are the building blocks of a system's architecture. Despite being simple and appealing, this view has proven to be incomplete and has required further elaboration. To that end, researchers have more recently tried to approach architectures from another important perspective---that of design decisions that yield a system's architecture. These more recent efforts have lacked a precise understanding of several key questions, however: (1) What is an architectural design decision (definition)? (2) How can architectural design decisions be found in existing systems (identification)? (3) What system decisions are and are not architectural (classification)? (4) How are architectural design decisions manifested in the code (reification)? (5) How can important architectural decisions be preserved and/or changed as desired (evolution)? This paper presents a technique targeted at answering these questions by analyzing information that is readily available about software systems. We applied our technique on over 100 different versions of two widely adopted open- source systems, and found that it can accurately uncover the architectural design decisions embodied in the systems.",
    "actual_venue": "Arxiv: Software Engineering"
  },
  {
    "abstract": "The recently proposed robust principal component analysis (RPCA) theory and its derived methods have attracted much attention in many computer vision and machine intelligence applications. From a wide view of these methods, independent motion objects are modeled as pixel-wised sparse or structurally sparse outliers from a highly correlated background signal, and all these methods are implemented under an l(1)-penalized optimization. Real data experiments reveal that even if l(1)-penalty is convex, the optimization sometimes cannot be satisfactorily solved, especially when the signal-to-noise ratio is relatively high. In addition, the unexpected background motion (e.g., periodic or stochastic motion) may also be included. We propose a moving object detection method based on a proximal RPCA along with saliency detection. Convex penalties including low-rank and sparse regularizations are substituted with proximal norms to achieve robust regression. After the foreground candidates have been extracted, a motion saliency map using spatiotemporal filtering is constructed. The foreground objects are then filtered out by dynamically adjusting the penalty parameter according to the corresponding saliency values. Evaluations on challenging video clips and qualitative and quantitative comparisons with several state-of-the-art methods demonstrate that the proposed approach works efficiently and robustly. (C) 2016 SPIE and IS&T",
    "actual_venue": "Journal Of Electronic Imaging"
  },
  {
    "abstract": "Semiotics studies the production, transmission and interpretation of meaning represented symbolically in signs and messages, primarily but not exclusively in language. For information systems (IS) the domain of semiosis consists of human and non-human interactions based on technologically-mediated communication in the social, material and personal worlds. The paper argues that semiosis has immense bearing on processes of communication central to the advanced information and communications technologies studied by IS scholars. Its use separately, or in mixed methods approaches, enriches areas of central concern to the IS field, and is particularly apt when researching internet-based development and applications, for example virtual worlds and social media. This paper presents a four step structured methodology, informed by a central theoretical semiotic framework to provide practical guidelines for operationalizing semiotics in IS research. Thus, using illustrative examples, the paper provides a step-by-step semiotics approach to research based on distinctive semiotic concepts and their relationships producer, consumer, medium, code, message and content and how, at an integrating level, the personal, social and material worlds relate through sociation, embodiment and socio-materiality. Develops practical guidelines for using semiotic concepts within IS researchDescribes many concepts that enable us to understand how meaning is conveyed consciously and unconsciouslyDescribes over thirty practical examples within IS and analyses some in detail",
    "actual_venue": "Information And Organization"
  },
  {
    "abstract": "This paper presents a new curve fitting framework for styling design data. Given a data set that represents a filleted-like curve, underlying curves (U-curves) and styling radius corners (SR-corners) are generated by fitting to low curvature parts and highly curved ones, respectively. A set of U-curves are firstly reconstructed as a unique (C^0) composite B-spline curve, and then an SR-corner is reconstructed for each (C^0) corner. This approach guarantees that U-curves can be smoothly connected through convex SR-corners while enabling full editing of the smooth corners up to sharp ones. Compared with existing schemes that naively fit a curve to each part, the proposed framework provides a guiding principle for the generation of curves, which is more suitable for styling design. Experimental results demonstrate that high-quality curves can be generated even from real-world scanned data.",
    "actual_venue": "The Visual Computer"
  },
  {
    "abstract": "Addressed in this paper is the robust  H  ∞  control issue of T-S fuzzy systems with input time-varying delays. By means of the delay partitioning method, the delay interval is partitioned into multiple unequal subintervals whose lengths satisfy a geometric sequence. On this basis, a modified Lyapunov–Krasovskii functional is presented to analyze asymptotic stability of the open-loop system. Then a state feedback controller that ensures a prescribed  H  ∞  performance level for the closed-loop system is proposed in linear matrix inequality format. Finally, two numerical examples are given to illustrate the effectiveness and advantages of the obtained results.",
    "actual_venue": "Applied Mathematics And Computation"
  },
  {
    "abstract": "As is well known, the semantics of documents are exposed to us in latent way. However, most existing hashing methods ignore this fact and thus fail to discover the hidden semantic structure. To overcome this issue, we pay more attention to discover its latent semantic structure when hashing for document corpus in this paper. We mainly adopt two measures to discover the hidden structures. On the one hand, the Laplacian graph constructed in semantic space rather than in term-document space is used to capture the semantic structure for document corpus during hashing. On the other hand, motivated by the fact that non-negative matrix factorization (NMF) is an effective algorithm to discover the latent semantic structure for documents, we employ NMF to extract a parts-based representation for document. In addition, to reduce semantic loss when mapping parts-based representation into Hamming space, we impose sparse constraints to make the element of parts-based representation more close to binary values. The experimental results demonstrate that the proposed hashing method is competitive with the state-of-the-art methods in document hashing.",
    "actual_venue": "Multimedia Tools Appl"
  },
  {
    "abstract": "Traditionally, there have been few options for navigational aids for the blind and visually impaired (BVI) in large indoor spaces. Some recent indoor navigation systems allow users equipped with smartphones to interact with low cost Bluetoothbased beacons deployed strategically within the indoor space of interest to navigate their surroundings. A major challenge in deploying such beacon-based navigation systems is the need to employ a time and labor-expensive beacon planning process to identify potential beacon placement locations and arrive at a topological structure representing the indoor space. This work presents a technique called IBeaconMap for creating such topological structures to use with beacon-based navigation that only needs the floor plans of the indoor spaces of interest. IBeaconMap employs a combination of computer vision and machine learning techniques to arrive at the required set of beacon locations and a weighted connectivity graph (with directional orientations) for subsequent navigational needs. Evaluations show IBeaconMap to be both fast and reasonably accurate, potentially proving to be an essential tool to be utilized before mass deployments of beacon-based indoor wayfinding systems of the future.",
    "actual_venue": "Arxiv: Human-Computer Interaction"
  },
  {
    "abstract": "In this paper, we propose a method for taking into account uncertainties based on the projection on polynomial chaos. The proposed method is used to determine the dynamic response of a spur gear system with uncertainty associated to friction coefficient on the teeth contact. We developed a lumped dynamic model with 8dofs. Lagrange formalism is used to formulate the governing equation of motion of the model. The simulation results are obtained by the polynomial chaos method for dynamic analysis under uncertainty. The polynomial chaos results are compared with Monte Carlo simulations.",
    "actual_venue": "Advances In Engineering Software"
  },
  {
    "abstract": "The combination of Network Function Virtualization (NFV) and Software Defined Networking (SDN) possesses a great potential in accommodating dynamic network control via cloning/migration of virtualized NFs and steering of traffic flows. A great challenge is the lack of the proprietary internal NF state information to the control system (including SDN controller and NFV orchestrator), which may lead to incorrect. packet/flow processing at the newly created NF instances. In this work, we design a light-weight approach which can function either independently or as a plug-in to the network control system to reveal the internal NF states. Unlike the previous work, we propose to learn the internal NF states through normal network functions instead of designing extra APIs for certain NFs. Moreover, we propose a feasible way to detect state violations and even correct them automatically. Our approach is tested by experiments, and the results confirm its efficiency and practicability.",
    "actual_venue": "Ieee Infocom"
  },
  {
    "abstract": "Industry 4.0, which exploits cyber-physical systems and represents digital transformation of manufacturing, is deeply affecting healthcare as well as other traditional production sector. To accommodate the increasing demand of agility, flexibility, and low cost in healthcare sector, a data-driven reconfigurable production mode of Smart Factory for pharmaceutical manufacturing is proposed in this p...",
    "actual_venue": "Ieee Transactions Industrial Informatics"
  },
  {
    "abstract": "Fault location algorithms require the input of voltage and current phasors when estimating the distance to a fault. In the case of momentary faults, phasor calculations are often complicated by the presence of an exponentially decaying dc offset. Fourier filters and cosine filters, popularly used by most phasor estimation algorithms in relays, are successful in filtering out most, but not all, of ...",
    "actual_venue": "Ieee Transactions On Smart Grid"
  },
  {
    "abstract": "Despite the several speedup methods proposed in the literature, the computational complexity of High Efficiency Video Coding (HEVC) video encoding is still a problem. This paper proposes a fast coding unit (CU) partition decision for use in HEVC encoders based on support vector machine (SVM)-trained offline. The SVM classifiers, features, and training procedures are described in detail, and a justification for the use of SVMs is provided. The trained classifiers are incorporated into a modified reference encoder in the form of a fast CU partition decision algorithm, which decides if the exhaustive search for the best partition is continued or terminated prematurely. Using the proposed method, an average complexity reduction of 48% is achieved with a 0.48% Bjontegaard-Delta bitrate (BD-BR) loss using the random access coding configuration, 44% reduction with a 0.62% BD-BR loss for the Low Delay B, and a 41% reduction with a 0.6% BD-BR loss for the Low Delay P configuration. We also tested our approach under constant bitrate conditions, achieving a 47% reduction in encoding time with a 1.11% loss in the BD-BR. In addition, a decision threshold adaptation is also proposed to allow adjusting the rate-distortion/complexity trade-off of our solution. With this approach, the computational complexity reduction can be varied from 34.9% (with a 0.13% loss in the BD-BR) up to 52.4% (with a 1.11% BD-BR loss) using the random access configuration. Compared with the state-of-the-art solutions, our decision scheme outperforms the related works in terms of combined rate distortion and complexity.",
    "actual_venue": "Ieee Transactions On Circuits And Systems For Video Technology"
  },
  {
    "abstract": "In this paper, the problem of function computation with privacy and secrecy constraints is considered. The considered model consists of three legitimate nodes (i.e., two transmitters, Alice and Bob, and a fusion center that acts as the receiver) that observe correlated sources and are connected by noiseless public channels, and an eavesdropper Eve who has full access to the public channels and also has its own source observations. The fusion center would like to compute a function of the distributed sources within a prefixed distortion level under a certain distortion metric. To facilitate the function computation, Alice and Bob will send messages to the fusion center. Different from the existing setups in function computation, we assume that there is a \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">privacy</italic>\n constraint on the sources at Alice and Bob. In particular, Alice and Bob would like to enable the fusion center to compute the function, but at same time, they do not want the fusion center to learn too much information about the source observations. We introduce a quantity to precisely measure the privacy leakage to the fusion center. In addition to this privacy constraint, we also have a \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">secrecy</italic>\n constraint to Eve and use equivocation of sources to measure this quantity. Under this model, we study the tradeoffs among message rates, private information leakage, equivocation, and distortion. We first consider a scenario that has only one transmitter, i.e., the source at Bob is empty, and fully single-letter characterize the corresponding regions. Then, we consider the more general case and provide both outer and inner bounds on the corresponding regions.",
    "actual_venue": "Ieee Transactions On Information Theory"
  },
  {
    "abstract": "We address a special kind of Internet of Things (IoT) systems that are also real-time. We call them real-time IoT (RT-IoT) systems. An RT-IoT system needs to meet timing constraints of system delay, clock synchronization, deadline, and so on. The timing constraints turn to be more stringent as we get closer to the physical things. Based on the reference architecture of IoT (ISO/IEC 30141), the RT-IoT conceptual model is established. The idea of edge subsystem is introduced. The sensing & controlling domain is the basis of the edge subsystem, and the edge subsystem usually must meet the hard real-time constraints. The model includes four perspectives, the time view, computation view, communication view, and control view. Each view looks, from a different angle, at how the time parameters impact an RT-IoT system.",
    "actual_venue": "Frontiers Of Information Technology And Electronic Engineering"
  }
]