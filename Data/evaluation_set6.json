[
  {
    "abstract": "We call shifted power a polynomial of the form (x−a)e. The main goal of this paper is to obtain broadly applicable criteria ensuring that the elements of a finite family F of shifted powers are linearly independent or, failing that, to give a lower bound on the dimension of the space of polynomials spanned by F. In particular, we give simple criteria ensuring that the dimension of the span of F is at least c.|F| for some absolute constant c<1. We also propose conjectures implying the linear independence of the elements of F. These conjectures are known to be true for the field of real numbers, but not for the field of complex numbers. The verification of these conjectures for complex polynomials directly imply new lower bounds in algebraic complexity.",
    "actual_venue": "Journal Of Complexity"
  },
  {
    "abstract": "This paper describes the first successfully implemented real-time Mandarin dictation machine developed in the world which recognizes Mandarin speech with very large vocabulary and almost unlimited texts for the input of Chinese characters into computers. Considering the special characteristics of the Chinese language, syllables are chosen as the basic units for dictation. The machine is speaker dependent, and the input speech is in the form of sequences of isolated syllables. The machine can be decomposed into two subsystems. The first subsystem is to recognize the syllables using hidden Markov models, in which special training algorithms and recognition approaches have been developed to recognize the 408 very confusing syllables (disregarding the tones), and special feature vectors have been used to recognize the five different tones including the very confusing neutral tone. But this does not help very much because every syllable can represent many different homonym characters and form different multi-syllabic words with syllables on its right or left. The second subsystem is then needed to identify the exact characters from the syllables and correct the errors in syllable recognition by first finding all possible word hypotheses and forming a word lattice for the sequence of recognized syllables through a lexical access process, and then obtaining the best path in the lattice with the maximum likelihood as the output sentence using a data-trained Markov Chinese language model. The real-time implementation is on an IBM PC/AT, connected to three sets of specially designed hardware boards on which seven TMS 320C25 chips operate in parallel. The preliminary test results indicate that it takes only about 0.45 s to dictate a syllable (or character) with an accuracy on the order of 90%. All techniques used in this machine are described and discussed in detail in this paper.",
    "actual_venue": "Ieee Transactions On Speech And Audio Processing"
  },
  {
    "abstract": "The advent (and promise) of shared, widely available, high-speed networks provides the potential for new approaches to the collection, organization, storage, and analysis of high-speed and high-volume data streams from high data-rate, on-line instruments. We have worked in this area for several years, have identified and addressed a variety of problems associated with this scenario, and have evolved an architecture, implementations, and a monitoring methodology that have been successful in addressing several different application areas.In this paper we describe a distributed, wide area network-based architecture that deals with data streams that originate from on-line instruments. Such instruments and imaging systems are a staple of modern scientific, health care, and intelligence environments. Our work provides an approach for reliable, distributed real-time analysis, cataloguing, and archiving of the data streams through the integration and distributed management of a high-speed distributed cache, distributed high-performance applications, and tertiary storage systems.",
    "actual_venue": "SC"
  },
  {
    "abstract": "This paper presents our approach to using semantic technologies to describe robot embodiments. We introduce a prototype implementation of RoboDB, a robot database based on semantic web technologies with the functionality necessary to store meaningful information about the robot's body structure. We present a heuristic evaluation of the user interface to the system, and discuss the possibilities of using the semantic information gathered in the database for applications like building a robot ontology, and the development of robot middleware systems.",
    "actual_venue": "HRI"
  },
  {
    "abstract": "Network resilience in MPLS/GMPLS networks has been receiving considerable attention Most of the previous research on GMPLS recovery management has focused on efficient routing or signaling methods from single failures Multiple simultaneous failures, however, may occur in a large-scale complex GMPLS network infrastructure In this article, we derived the condition to test the existence of backup segments which satisfy the resilience constraint under multiple link failures, in a general mesh-type MPLS/GMPLS network A decomposition theorem and a backup segment construction algorithm have been developed for the fast restoration of resilience-guaranteed backup segments, for the primary path with an arbitrary configuration Finally, the simulation has been to show the efficiency of the proposed approach.",
    "actual_venue": "Icoin"
  },
  {
    "abstract": "Industrial reports indicate that security incidents continue to inflict large financial losses on organizations. Researchers and industrial analysts contend that there are fundamental problems with existing security incident response process solutions. This paper presents the Security Incident Response Criteria (SIRC) which can be applied to a variety of security incident response approaches. The criteria are derived from empirical data based on in-depth interviews conducted within a Global Fortune 500 organization and supporting literature. The research contribution of this paper is twofold. First, the criteria presented in this paper can be used to evaluate existing security incident response solutions and second, as a guide, to support future security incident response improvement initiatives.",
    "actual_venue": "Association For Information Systems"
  },
  {
    "abstract": "We introduce an alternative approach to extracting word pair associations from corpora, based purely on surface distances in the text. We contrast it with the prevailing window-based co-occurrence model and show it to be more statistically robust and to disclose a broader selection of significant associative relationships - owing largely to the property of scale-independence. In the process we provide insights into the limiting characteristics of window-based methods which complement the sometimes conflicting application-oriented literature in this area.",
    "actual_venue": "Eacl"
  },
  {
    "abstract": "Metabolic P systems are a special class of P systems which seem to be adequate for expressing biological phenomena related to metabolism and signaling transduction in biological systems. We give the basic motivation for their introduction and some ideas about their applicability to some basic biological oscillators.",
    "actual_venue": "Workshop On Membrane Computing"
  },
  {
    "abstract": "We introduce a new graph parameter, called the Grothendieck constant of a graph G=(V,E), which is defined as the least constant K such that for every A:E→ℝ, \n \n \n \n \n $$\\sup_{f:V\\to{S}^{|V|-1}}\\sum_{\\{u,v\\}\\in{E}} A(u,v)\\cdot\\langle{f(u),f(v)}\\rangle\\le{K}\\sup_{\\varphi:V\\to\\{-1,+1\\}}\\sum_{\\{u,v\\}\\in{E}}A(u,v)\\cdot\\varphi(u)\\varphi(v).$$\n \n \n \n \n \n  The classical Grothendieck inequality corresponds to the case of bipartite graphs, but the case of general graphs is shown to have various algorithmic applications. Indeed, our work is motivated by\n the algorithmic problem of maximizing the quadratic form ∑{u,v}∈EA(u,v)ϕ(u)ϕ(v) over all ϕ:V→{-1,1}, which arises in the study of correlation clustering and in the investigation of the spin glass model. We give upper\n and lower estimates for the integrality gap of this program. We show that the integrality gap is \n \n , where \n \n is the Lovsz Theta Function of the complement of G, which is always smaller than the chromatic number ofG. This yields an efficient constant factor approximation algorithm for the above maximization problem for a wide range of\n graphs G. We also show that the maximum possible integrality gap is always at least Ω(log ω(G)), where ω(G) is the clique number of G.\n In particular it follows that the maximum possible integrality gap for the complete graph on n vertices with no loops is Θ(logn). More generally, the maximum possible integrality gap for any perfect graph with chromatic number n is Θ(logn). The lower bound for the complete graph improves a result of Kashin and Szarek on Gram matrices of uniformly bounded functions,\n and settles a problem of Megretski and of Charikar and Wirth.",
    "actual_venue": "Acm Symposium On Theory Of Computing"
  },
  {
    "abstract": "We consider the OMG's Queries, Views and Transformations (QVT) standard as applied to the specification of bidirectional transformations between models. We discuss what is meant by bidirectional transformations, and the model-driven development scenarios in which they are needed. We analyse the fundamental requirements on tools which support such transformations, and discuss some semantic issues which arise. We argue that a considerable amount of basic research is needed before suitable tools will be fully realisable, and suggest directions for this future research.",
    "actual_venue": "Software And System Modeling"
  },
  {
    "abstract": "Although e-learning has been prompted to various education levels, the intention to continue using such systems is still very low, and the acceptance-discontinuance anomaly phenomenon (i.e., users discontinue using e-learning after initially accepting it) is a common occurrence. This paper synthesizes the expectation-confirmation model (ECM), the technology acceptance model (TAM), the theory of planned behavior (TPB), and the flow theory to hypothesize a theoretical model to explain and predict the users' intentions to continue using e-learning. The hypothesized model is validated empirically using a sample collected from 363 learners of a Web-based learning program designed for continuing education. The results demonstrate that satisfaction has the most significant effect on users' continuance intention, followed by perceived usefulness, attitude, concentration, subjective norm, and perceived behavior control as significant but weaker predictors. The implications of these findings for e-learning practitioners are discussed at the end of this work.",
    "actual_venue": "Computers In Education"
  },
  {
    "abstract": "Part mating with a multifingered gripper mainly comprises two areas, i.e., the control of the gripper or hand and the strategies to solve the task. The problem is made more difficult by the uncertainties from mechanical, sensor or control errors within the gripper system or the parts to be assembled. The authors examine how to find and to realize a hand behavior, which solves the task under the assumption that the system is heavily influenced by the uncertainties mentioned. The problem is solved by a force feedback loop, containing a comparatively simple mathematic description of strategies applied in parallel. The proof of the efficiency of the approach is given. Results of various experiments are presented",
    "actual_venue": "Atlanta, Ga"
  },
  {
    "abstract": "The rich spectral information in hyperspectral imagery gives rise to huge storage and transmission costs. Dimensionality reduction aims to reduce the space complexity in hyperspectral imagery by projecting data into a low-dimensional subspace. There has been an increasing interest in dimensionality reduction driven by random projections due to its dataindependent representation as well as desirable qualities such as the preservation of important information and low computational costs. The performance of a random projection derived from a Hadamard-Walsh matrix is investigated, with experimental results demonstrating classification performance superior to other random dimensionality-reduction methods when deployed in conjunction with a composite-kernel support vector machine that exploits both spatial and spectral information for the classification of hyperspectral imagery.",
    "actual_venue": "Ieee International Geoscience And Remote Sensing Symposium"
  },
  {
    "abstract": "A 1-Gb/s 0.18- mum CMOS serial-link transceiver using multilevel pulse-width and pulse-amplitude modulation (PWAM) signaling and a pre-emphasis technique is presented. Based on the PWAM technique, the transmit signaling is implemented to effectively push high data rates through bandwidth- limited channels. The clock is implicitly embedded in the 4-bit data stream, and the associated overhead needed in the clock-and-data recovery circuitry can be mitigated. In addition, the pin count can be reduced by transferring the data channels and the clock channel over a single transmitted channel. The recovered clock has an rms jitter of 5.9 ps at 250 MHz, and the retimed data have an rms jitter of 13.7 ps at 250 Mb/s. The occupied die area is 1.65 X 1.40 mm2. The transmitter and receiver power consumption is 86 and 45 mW, respectively.",
    "actual_venue": "Ieee T Instrumentation And Measurement"
  },
  {
    "abstract": "In this paper, the inverse problem of recovering the potential function, on a general finite interval, of a singular Sturm-Liouville problem with a new spectral parameter, called the nodal point, is studied. In addition, we give an asymptotic formula for nodal points and the density of the nodal set.",
    "actual_venue": "Mathematical And Computer Modelling"
  },
  {
    "abstract": "VisageWeb is an information-centric user interface to the World Wide Web built within the Visage data visualization environment. This paper traces the development of the VisageWeb project, using it to motivate an exploration of how an information-centric architecture copes with new visualization challenges. We conclude with a presentation of the VisageWeb prototype itself.",
    "actual_venue": "Infovis"
  },
  {
    "abstract": "While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human's gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them.",
    "actual_venue": "Advances In Neural Information Processing Systems"
  },
  {
    "abstract": "In large scale wireless sensor networks, retransmission strategies are widely adopted to guarantee the reliability of multi-hop forwarding. However, keeping retransmission over a bursty link may fail consecutively. Moreover, the retransmission will also be useless over those back-up links which are spatial correlated with the failed link. Thus, it is necessary to design an unified retransmission strategy, which considers both temporal and spacial link properties, to further improve network reliability and efficiency. In this paper, we propose RxLayer, a practical and general supporting layer of data retransmission. Without inducing noticeable overhead, RxLayer captures the temporal and spatial link properties by conditional probability models. A sender will retransmit data over the candidate link with the highest delivery probability while failures occur. RxLayer can be transparently integrated with most of the existing forwarding protocols. We implement RxLayer and evaluate it on both indoor and outdoor testbeds. The results show that RxLayer improves networks reliability and energy efficiency in various scenarios. The network reliability is improved by up to 7.82%, and the total number of transmissions is reduced by up to 36.3%.",
    "actual_venue": "Mobihoc"
  },
  {
    "abstract": "This Mediadrom artful post-TV scenario consists in sketching the user interface of an interactive media content browsing system for exploring thematically sorted artworks, from the art field of plastic theater, merging art pieces at the intersection of the visual and the performing arts. Combining a touchscreen and an hypermedia browser of image and video content with expert annotations, this system can be installed in venues such as museum and media libraries, and performance spaces as satellite installation to plastic theater performances.",
    "actual_venue": "MMM (2)"
  },
  {
    "abstract": "novel R-GPLVM is proposed to screen out critical dimensions of the preform.A newly GA-ELM framework seamlessly integrated with R-GPLVM is proposed.Discussions demonstrate that Gaussian kernel function has the higher accuracy.The relevant parameters of ELM are optimized with the improved performance.Engineering applications and FEM validate the feasibility of the proposed method. The determination of the key dimensions of gear blank preforms with complicated geometries is a highly nonlinear optimization task. To determine critical design dimensions, we propose a novel and efficient dimensionality reduction (DR) model that adapts Gaussian process regression (GPR) to construct a topological constraint between the design latent variables (LVs) and the regression space. This procedure is termed the regression-constrained Gaussian process latent variables model (R-GPLVM), which overcomes GPLVM's drawback of ignoring the regression constrains. To determine the appropriate sub-manifolds of the high-dimensional sample space, we combine the maximum a posteriori method with the scaled conjugate gradient (SCG) algorithm. This procedure can estimate the coordinates of preform samples in the space of LVs. Numerical experiments reveal that the R-GPLVM outperforms the pure GPR in various dimensional spaces, when the proper hyper-parameters and kernel functions are solved for. Results using an extreme learning model (ELM) obtain a better prediction precision than the back propagation method (BP), when the dimensions are reduced to seven and a Gaussian kernel function is adopted. After the seven key variables are screened out, the ELM model will be constructed with realistic inputs and obtains improved prediction accuracy. However, since the ELM has a problem with validity of the prediction, a genetic algorithm (GA) is exploited to optimize the connection parameters between each network layer to improve the reliability and generalization. In terms of prediction accuracy for testing datasets, GA has a better performance compared to the differential evolution (DE) approach, which motivates the choice to use the genetic algorithm-extreme learning model (GA-ELM). Moreover, GA-ELM is employed to measure the aforementioned DR using engineering criteria. In the end, to obtain the optimal geometry, a parallel selection method of multi-objective optimization is proposed to obtain the Pareto-optimal solution, while the maximum finisher forming force (MFFF) and the maximum finisher die stress (MFDS) are both minimized. Comparative analysis with other numerical models including finite element model (FEM) simulation is conducted using the GA optimized preform. Results show that the values of MFFF and MFDS predicted by GA-ELM and R-GPLVM agree well with the experimental results, which validates the feasibility of our proposed methods.",
    "actual_venue": "Knowledge Based Systems"
  },
  {
    "abstract": "The practical application and implementation of online distributed system-level diagnosis theory is documented. Proven distributed diagnosis algorithms are shown to be impractical in real systems due to high resource requirements. A distributed system-level diagnosis algorithm called Adaptive DSD is shown to minimize network resources and has resulted in a practical implementation. Adaptive DSD assumes a distributed network, in which network nodes can test other nodes and determine them to be faulty or fault-free. Tests are issued from each node adaptively and depend on the fault situation of the network. Test result reports are generated from test results and forwarded between nodes in the network. Adaptive DSD is proven correct in that each fault-free node reaches an accurate independent diagnosis of the fault conditions of the remaining nodes. No restriction is placed on the number of faulty nodes; any fault situation with any number of faulty nodes is diagnosed correctly. An implementation of the Adaptive DSD algorithm is described.",
    "actual_venue": "Ieee Transactions On Computers - Special On Fault-Tolerant Computing"
  },
  {
    "abstract": "This paper presents a robust fault-tolerant control method for a class of uncertain switched systems with strong structural uncertainties using average dwell-time method. Due to the nature of average dwell-time techniques and the representation of actuator faults, this paper has the following features compared with the existing methods in the literature: 1) the proposed controller exponentially stabilizes this class of nonlinear systems containing strong uncertainties with actuator faults and its nominal (i.e., without actuator faults) systems without necessarily changing any structures and/or parameters of the proposed controllers; 2) the proposed method is independent of arbitrary switching polices provided that switching is on-the-average slow enough; 3) the proposed method treats all actuators in a unified way without necessarily classifying all actuators into faulty actuators and healthy ones. A numerical example is provided to show the effectiveness of the proposed method. © 2013 TCCT, CAA.",
    "actual_venue": "Control Conference"
  },
  {
    "abstract": "A root-locus approach is adopted to show that extension of Kharitonov-type theorem for real interval polynomial with degree drop is not only applicable to the open left-half plane, but also other regions such as the left-shifted open left-half plane and the left sector.",
    "actual_venue": "Systems And Control Letters"
  },
  {
    "abstract": "We modify an old algorithm for expanding powers of dense polynomials to make it work for sparse polynomials, by using a heap to sort monomials. It has better complexity and lower space requirements than other sparse powering algorithms for dense polynomials. We show how to parallelize the method, and compare its performance on a series of benchmark problems to other methods and the Magma, Maple and Singular computer algebra systems.",
    "actual_venue": "Casc"
  },
  {
    "abstract": "For finite and compact infinite metric spaces, a concept of a (weighted) tau-design is introduced which depends on a choice of a substitution function. To estimate the minimum size of a tau-design a system of orthogonal polynomials is defined using the average measure of metric balls and the substitution function. A universal lower bound on the size of tau-designs is obtained with the help of the solution of the known extremum problem for systems of orthogonal polynomials. The concept of a tau-design and the bound considered coincide with those in the case of polynomial association schemes of Delsarte and the Euclidean sphere for the proper choices of the substitution functions. This bound is also calculated for some other spaces. (C) 1998 Elsevier Science B.V. All rights reserved.",
    "actual_venue": "Discrete Mathematics"
  },
  {
    "abstract": "A lot of studies have been made to characterize and model sources of ATM traffic (voice, data, video) and to evaluate the performance of a multiplexer whose input is a superposition of these sources, using different methods and techniques (fluid flow, matrix-analytic, etc.). However, in order to better understand the end-to-end performance of ATM connections, characterizations and models of ATM traffic inside the network (i.e. after passage through one or more network elements) are needed. In this paper we intend to study the following problems: (i) Traffic profile of an ATM connection after being policed, in particular worst case traffic, and evaluation of the performance of the related statistical multiplexer. (ii) Traffic profile of the output of a multiplexer (characterized by means of the interdeparture time distribution and the index of dispersion for counts and the index of dispersion for interarrival times). (iii) Traffic profile of a single connection after passing a multiplexer. The aim is to obtain useful characterizations and models of ATM traffic in order to evaluate the performance and the efficiency of ATM network elements and of traffic control functions.",
    "actual_venue": "Telecommunication Systems"
  },
  {
    "abstract": "Different sorts of large transactions can be found in object management systems, i.e. databases for engineering design systems. Examples are design transactions, tool executions and operations on complex objects. Such transactions should not run into deadlocks because their rollback is very expensive. We propose a solution which is based on two-phase locking with pseudo-preclaiming, a variant of preclaiming, in which locks are acquired concurrently with the running transaction. One main problem is to find a deadlock-free lock acquistion strategy which has the “immediate granting property”; this means that locks which are requested on unlocked objects are granted immediately. We show the queue protocol has this property. Finally, we show how deadlocks can be prevented, or made, at least, less probable, if further locks are requested after the preclaiming operation or if navigation is required to determine the set of objects used by a transaction.",
    "actual_venue": "Inf Syst"
  },
  {
    "abstract": "Recently, the watermarking is an important technique to protect copyright, which allows authentic watermark to be hidden in multimedia such as digital image, video and audio. In this paper, we propose a DWT-based counter-propagation neural network (CPN) for digital audio watermarking. The db4 filter of the Daubechies wavelet is applied in this paper. The coefficients obtained from 4-level db4 and the corresponding watermark is used for training the CPN. Different from the traditional methods, the watermark is embedded in the synapses of CPN instead of the original audio signal. In addition, because of the watermark is memorized in the synapses, most of the attacks are not degrade the quality of the extracted watermark image. Moreover, the watermark embedding procedure and extracting procedure are integrated into the proposed CPN. Experimental results show that the proposed method has capabilities of robustness, inaudibility and authenticity.",
    "actual_venue": "SMC"
  },
  {
    "abstract": "This paper studies a hierarchical distributed choice of retransmission probabilities in slotted aloha. In particular, we consider a wireless system composed of one central receiver and several selfish mobile users communicating via the slotted aloha protocol. The set of mobile users is split into two classes: leaders and followers. We then study the induced non-cooperative hierarchical game based on the Stackelberg equilibrium concept. Using a 4D Markovian model, we compute the steady state of the system and derive the average throughput and the expected delay as well. We start by discussing the protocol design and propose a controlled slotted aloha using a virtual controller. The virtual controller can sustain partial cooperation among concurrent mobile users when accessing the channel by making the channel lossy. This leads us to identify a Braess-like paradox in which reducing capacity to the system may improve the performance of all mobile users. We then investigate the impact of hierarchy among mobile users in such a random access protocol and discuss how to distribute leader/follower roles. We show that the global performance of the system is improved compared to standard slotted aloha system. However, slight performances slow-down may be observed for the followers group when the total number of mobile users is relatively small.",
    "actual_venue": "Computer Communications"
  },
  {
    "abstract": "Reactive navigation based on task decomposition is an effective means for producing robust navigation in complex domains. By incorporating various forms of knowledge, this technique can be made considerably more flexible. Behavioral and perceptual strategies which are represented in a modular form and configured to meet the robot's mission and environment add considerable versatility. A priori world knowledge, when available, can be used to configure these strategies in an efficient form. Dynamically acquired world models can be used to circumvent certain pitfalls that representationless methods are subject to. The Autonomous Robot Architecture (AuRA) is the framework within which experiments in the application of knowledge to reactive control are conducted. Actual robot experiments and simulation studies demonstrate the flexibility and feasibility of this approach over a wide range of navigational domains.",
    "actual_venue": "Robotics And Autonomous Systems"
  },
  {
    "abstract": "Topographic regularity is a fundamental property in brain connectivity. In this work, we present a novel method for studying topographic regularity of functional connectivity based on resting-state fMRI (rfMRI), which is widely available and easy to acquire in large-scale studies. The main idea in our method is the incorporation of topographically regular structural connectivity for independent component analysis (ICA). This is enabled by the recent development of novel tractography and tract filtering algorithms that can generate highly organized fiber bundles connecting different brain regions. By leveraging these cutting-edge tractography algorithms, here we develop a kernel-regularized ICA method for the extraction of functional topography with rfMRI signals. In our experiments, we use rfMRI scans of 35 unrelated, right-handed subjects from the Human Connectome Project (HCP) to study the functional topography of the motor cortex. We first demonstrate that our method can generate functional connectivity maps with more regular topography than conventional group ICA. We also show that the components extracted by our algorithm are able to capture co-activation patterns that respect the organized topography of the motor cortex across the hemisphere. Finally, we show that our method achieves improved reproducibility as compared to conventional group ICA.",
    "actual_venue": "Miccai"
  },
  {
    "abstract": "Eudaemon is a technique that aims to blur the borders between protected and unprotected applications, and brings together honeypot technology and end-user intrusion detection and prevention. Eudaemon is able to attach to any running process, and redirect execution to a user-space emulator that will dynamically instrument the binary by means of taint analysis. Any attempts to subvert control flow, or to inject malicious code will be detected and averted. When desired Eudaemon can reattach itself to the emulated process, and return execution to the native binary. Selective emulation has been investigated before as a mean to heal an attacked program or to generate a vaccine after an attack is detected, by applying intensive instrumentation to the vulnerable region of the program. Eudaemon can move an application between protected and native mode at will, e.g., when spare cycles are available, when a system policy ordains it, or when it is explicitly requested. The transition is performed transparently and in very little time, thus incurring minimal disturbance to an actively used system Systems offering constant protection against similar attacks have also been proposed, but require access to source code or explicit operating system support, and often induce significant performance penalties We believe that Eudaemon offers a flexible mechanism to detect a series of attacks in end-user systems with acceptable overhead. Moreover, we require no modification to the running system and/or installation of a hypervisor, with an eye on putting taint analysis within reach of the average user.",
    "actual_venue": "Proceedings Of The Acm Sigops/Eurosys European Conference On Computer Systems"
  },
  {
    "abstract": "Privacy protection is one of the most prominent concerns for web users. Despite numerous efforts, users remain powerless in controlling how their personal information should be used and by whom, and find limited options to actually opt-out of dominating service providers, who often process users information with limited transparency or respect for their privacy preferences. Privacy languages are designed to express the privacy-related preferences of users and the practices of organisations, in order to establish a privacy-preserved data handling protocol. However, in practice there has been limited adoption of these languages, by either users or data controllers. This survey paper attempts to understand the strengths and limitations of existing policy languages, focusing on their capacity of enabling users to express their privacy preferences. Our preliminary results show a lack of focus on normal web users, in both language design and their tooling design. This systematic survey lays the ground work for future privacy protection designs that aim to be centred around web users for empowering their control of data privacy.",
    "actual_venue": "Www : International World Wide Web Conference Montral Qubec Canada April"
  },
  {
    "abstract": "Call-by-push-value (CBPV) is a new paradigm, which has been claimed to provide the semantic primitives from which call-by-value and call-by-name are built. We present its operational semantics in the form of a Felleisen-Friedman style CK-machine, and see how this machine suggests a new term judgement of stacks. When augmented with this judgement, CBPV has an elegant categorical semantics based on adjunctions.",
    "actual_venue": "Electronic Notes In Theoretical Computer Science"
  },
  {
    "abstract": "Screen is becoming a new dimension in cloud computing platforms, and low latency screen sharing in unreliable networks is becoming more and more important. Due to the different characteristics between the screen codecs and video codecs, current transmission technologies on low-latency video streaming cannot be directly applied to screen sharing. So in this paper we first theoretically analyze the difference in latency performance between ARQ and FEC for the UDP-based screen sharing. Then, considering the characteristics of the main-stream screen codecs, we propose an improved ARQ scheme to decrease the transmission latency. The experimental results show that the proposed system achieves better latency performance than the popular systems.",
    "actual_venue": "Ieee International Symposium On Circuits And Systems"
  },
  {
    "abstract": "Context-aware systems gather data from their surrounding environments in order to offer completely new opportunities in the development of end user applications. Used in conjunction with mobile devices, these systems are of great value and increase usability. Applications and services should adapt to changing conditions within dynamic environments. This article analyzes the important aspects of context-aware computing and shows how it can be applied to monitor dependent individuals in their home. The proposed system logically processes the data it receives in order to identify and maintain a permanent location on the patient in the home, managing the infrastructure of services both safely and securely.",
    "actual_venue": "Iwinac"
  },
  {
    "abstract": "For geostationary meteorological satellite (GSMS) remote sensing image registration, high computational cost and matching error are the two main challenging problems. To address these issues, this paper proposes a novel algorithm named slope-restricted multi-scale feature matching. In multi-scale feature matching, images are subsampled to different scales. From a small scale to a large scale, the offsets between the matched pairs are used to narrow the searching area of feature matching for the next larger scale. Thus, the feature matching is accomplished from coarse to fine, which will make the matching process more accurate and reduce errors. To enhance the matching performance, the outliers in the matched pairs are rectified by using slope-restricted rectification, which is based on local geometric similarity. Compared with other algorithms, the experimental results show that our proposed method is more accurate and efficient.",
    "actual_venue": "Remote Sensing"
  },
  {
    "abstract": "Adaptive radio resource management policy aware of the demand for wireless services is termed dynamic spectrum access (DSA). In order to evaluate the effectiveness of DSA, dynamics of the demand should be considered. In the present paper, dynamics of the spectrum market, which is a way to realize DSA, are evaluated from the economic perspective. Modeling the spectrum market system by using game theory, the convergence characteristics of the system are analyzed from two points of view: allocation interval and prediction period. The available spectrum is allocated at regular time intervals and the length of this allocation interval naturally has a significant impact on the dynamics of the system. Also, available spectrum is allocated based on the prediction of the time variation of the demand for wireless services. This prediction thus influences the dynamics of the system. Simulation results reveal that short allocation interval and long prediction period are required to improve the convergence property of the system. Simulation results also reveal that long prediction period leads to the increase in the revenue of spectrum holder.",
    "actual_venue": "Globecom"
  },
  {
    "abstract": "In this paper we show how to accurately track position and orientation of a mobile robot using positioning only RF ultrasound transceiver system and dead-reckoning. The solution is based on geometrical displacement of the positioning device from the axis of rotation of the robot which brings dependency in position of the device and robot's orientation and enables the correction of the absolute orientation of the robot. Estimation is done via extended Kalman filter with variable discretization time because of stochastic nature of measurement arrival times. We describe and analyze the main sources of noise in odometry and position device readings. We also suggest the method for measurement outlier elimination derived from empirical measurement analysis. Experimental verification of the proposed method is presented that yields position error aprox. 1plusmn2.5 centimeters and 1plusmn2 degrees.",
    "actual_venue": "Cca) And Intelligent Control"
  },
  {
    "abstract": "The deployment of Internet based applications calls for adequate users management procedures, being online registration a critical element. In this respect, Email Based Identification and Authentication (EBIA) is an outstanding technique due to its usability. However, it does not handle properly some major issues which make it unsuitable for systems where security is of concern. In this work we modify EBIA to propose a protocol for users registration. Moreover, we assess the security properties of the protocol using the automatic protocol verifier ProVerif. Finally, we show that the modifications applied to EBIA are necessary to ensure security since, if they are removed, attacks on the protocol are enabled. Our proposal keeps the high usability features of EBIA, while reaching a reasonable security level for many applications. Additionally, it only requires minor modifications to current Internet infrastructures.",
    "actual_venue": "Knowl-Based Syst"
  },
  {
    "abstract": "Communication is a critical success factor in design. It can be seen as the social and cognitive process by which information is selected, messages are exchanged between interacting partners, and meaning is created. How communication processes can best be captured, analysed and assessed, as a preliminary step toward suggestions for improvement of communication practices, remains a challenge for researchers and practitioners. To this end, a maturity grid-inspired approach to audit communication practices has been developed. This paper employs a maturity grid approach and reflects critically on the construction and application of the approach in a structured group workshop in software design. Such an approach yields dual benefits: (a) as a research method to gather insight into communication and (b) as a guide to plan improvements in practice. Conclusions are drawn for the process of auditing communication in design.",
    "actual_venue": "Expert Systems With Applications"
  },
  {
    "abstract": "We develop an efficient iterative water-filling algorithm to find an optimal transmit spectrum for maximum sum capacity in a Gaussian multiple access channel with vector inputs and a vector output. The iterative algorithm converges from any starting point and reaches within (K-1)/2 nats per output dimension from the K-user sum capacity after just one iteration",
    "actual_venue": "Ieee Transactions On Information Theory"
  },
  {
    "abstract": "The methodologies for the generation of model describing two echoes of MR pathological images of the head are presented. A vocabulary set has been chosen and formalized consisting of attributes and relations for the characterization of the organs and tissues contained in the image. The analitic study of a training set of images, associated with expert aid for medical aspects has permitted the creation of the model whose robustness has been proved on a set of test images. The most important and innovative characteristics of the model are the hierarchical subdivision between organ-father and sub-organs, together with the distinction between anatomical and acquisition-dependent properties of the image.",
    "actual_venue": "Ipmi"
  },
  {
    "abstract": "In this paper, we present a temperature-driven simulation framework for power and timing analysis of CMOS ULSI circuits. A Monte-Carlo based power and temperature iteration methodology is first employed for finding the nominal steady-state on-chip temperature profile. The temperature information and the input vectors used in power analysis are then utilized for temperature-dependent timing analysis. Simulation results show that the on-chip temperature gradient and temperature rise has great impact on circuit timing, and our tool provides important guidelines for thermally reliable ULSI circuit design and to enhance the overall chip performance",
    "actual_venue": "Iscas"
  },
  {
    "abstract": "When assigning vehicles to transportation requests, dispatchers usually have built-in fuzzy rules which they use to assign a given amount of freight to be sent to a given distance a given vehicle. Fuzzy systems equipped with learning capabilities can be trained to control complex processes like the dispatcher. They usually begin with a few very crude rules obtained from the dispatcher. Or they may work out the rules from the observed dispatcher's behavior. In this paper, a neural network is used to refine and adapt the fuzzy system to achieve better performance. As a result of the study, on a real set of numerical data, it was shown that the proposed feedforward adaptive neural networks with supervised learning capabilities can be used to tune the initial fuzzy systems.",
    "actual_venue": "European Journal Of Operational Research"
  },
  {
    "abstract": "The essential issues of time complexity and probing signal selection are studied for persistent identification of linear time-invariant systems in a closed-loop setting. By establishing both upper and lower bounds on identification accuracy as functions of the length of observation, size of unmodeled dynamics, and stochastic disturbances, we demonstrate the inherent impact of unmodeled dynamics on identification accuracy, reduction of time complexity by stochastic averaging on disturbances, and probing capability of full rank periodic signals for closed-loop persistent identification. These findings indicate that the mixed formulation, in which deterministic uncertainty of system dynamics is blended with random disturbances, is beneficial to reduction of identification complexity.",
    "actual_venue": "Automatica"
  },
  {
    "abstract": "We compare the abstract speciflcations of four similar systems with similar capabilities, and give transformations which allow any implementation of a particular system to transform into certain other systems. This clarifles the relationships between the systems, which have often been casually grouped together in the literature.",
    "actual_venue": "Iacr Cryptology Eprint Archive"
  },
  {
    "abstract": "We address the problem of forecasting high-dimensional functional time series through a two-fold dimension reduction procedure. The difficulty of forecasting high-dimensional functional time series lies in the curse of dimensionality. In this paper, we propose a novel method to solve this problem. Dynamic functional principal component analysis is first applied to reduce each functional time series to a vector. We then use the factor model as a further dimension reduction technique so that only a small number of latent factors are preserved. Classic time series models can be used to forecast the factors and conditional forecasts of the functions can be constructed. Asymptotic properties of the approximated functions are established, including both estimation error and forecast error. The proposed method is easy to implement, especially when the dimension of the functional time series is large. We show the superiority of our approach by both simulation studies and an application to Japanese age-specific mortality rates.",
    "actual_venue": "Journal Of Multivariate Analysis"
  },
  {
    "abstract": "A fine symbol timing recovery (F-STR) algorithm with near timing-jitter free is proposed, which includes three parts: A Gardner TR circuit with a new- designed pre-filter as a ppm searcher, a high-order interpolation as an ideal re-sampler, and a segment sync or frame sync based STR circuit as an offset compensator. It can provide a near timing-jitter free property and its complexity can be further simplified by combining the last two units as one. Simulation results show that the proposed fine STR scheme is robust to noise and echoes. With a comparable complexity compared with previous arts, the proposed fine STR algorithm could give about 0.2 dB enhancements in terms oj symbol error rates (SER) and low bound of convergence can be improved by over I dB for Brazil B channel. Using the F-STR algorithm, receivers become feasible with large timing errors and severe echoes'.",
    "actual_venue": "Ieee Trans Consumer Electronics"
  },
  {
    "abstract": "The results of the IJCAR ATP System Competition are presented.",
    "actual_venue": "J Autom Reasoning"
  },
  {
    "abstract": "We have proposed a decision tree classifier named MMC (multi-valued and multi-labeled classifier) before. MMC is known as its capability of classifying a large multi-valued and multi-labeled data. Aiming to improve the accuracy of MMC, this paper has developed another classifier named MMDT (multi-valued and multi-labeled decision tree). MMDT differs from MMC mainly in attribute selection. MMC attempts to split a node into child nodes whose records approach the same multiple labels. It basically measures the average similarity of labels of each child node to determine the goodness of each splitting attribute. MMDT, in contrast, uses another measuring strategy which considers not only the average similarity of labels of each child node but also the average appropriateness of labels of each child node. The new measuring strategy takes scoring approach to have a look-ahead measure of accuracy contribution of each attribute's splitting. The experimental results show that MMDT has improved the accuracy of MMC.",
    "actual_venue": "Expert Syst Appl"
  },
  {
    "abstract": "Discovering underlying communities in networks is an important task in network analysis. In the last decade, a large variety of algorithms have been proposed. However, most of them require global information or a centralized control. Those algorithms are infeasible in large-scale real networks due to computation and accessibility. In this paper, we propose a novel decentralized community detection algorithm based on information diffusion. We believe information diffusion in human society can allow us to understand the emergence of community structure. Being able to find out some critical nodes which play an important role in the formation of a community is an important byproduct for our algorithm. Experiments on various networks, including benchmark networks and synthetic networks, show that it is comparable to three decentralized algorithms and two representative centralized algorithms, in terms of stability and accuracy. © 2011 IEEE.",
    "actual_venue": "Fskd"
  },
  {
    "abstract": "Financial credit-risk evaluation is among a class of problems known to be semi-structured, where not all variables that are used for decision-making are either known or captured without error. Machine learning has been successfully used for credit-evaluation decisions. However, blindly applying machine learning methods to financial credit risk evaluation data with minimal knowledge of data may not always lead to expected results. We present and evaluate some data and methodological considerations that are taken into account when using machine learning methods for these decisions. Specifically, we consider the effects of preprocessing of credit-risk evaluation data used as input for machine learning methods.",
    "actual_venue": "Expert Syst Appl"
  },
  {
    "abstract": "This paper presents a framework for resource management in highly dynamic active networks. The goal is to allocate and manage node resources in an efficient way while ensuring effective utilization of network and supporting load balancing. The framework supports co-existence of active and non-active nodes and proposes a novel Directory Service (DS) architecture that can be used to discover the suitable active nodes in the Internet and for selecting the best network path (end-to-end) and reserving the resources along the selected path. Intranode and internode resource management are facilitated through the DS, while within an active node the framework implements a composite scheduling scheme to schedule both the CPU and bandwidth resources to resolve the combined resource scheduling problems. In addition, a flexible active node database system and a simple adaptive prediction technique have been introduced in order to resolve the challenging problem of determining the CPU requirements of the incoming packets.",
    "actual_venue": "Telecommunication Systems"
  },
  {
    "abstract": "In rotor walk on a finite directed graph, the exits from each vertex follow a prescribed periodic sequence. Here we consider the case of rotor walk where a particle starts from a designated source vertex and continues until it hits a designated target set, at which point the walk is restarted from the source. We show that the sequence of successively hit targets, which is easily seen to be eventually periodic, is in fact periodic. We show moreover that reversing the periodic patterns of all rotor sequences causes the periodic pattern of the hitting sequence to be reversed as well. The proofs involve a new notion of equivalence of rotor configurations, and an extension of rotor walk incorporating time-reversed particles.",
    "actual_venue": "The Electronic Journal Of Combinatorics"
  },
  {
    "abstract": "In Turkish, (and possibly in many other languages) verbs often convey several\nmeanings (some totally unrelated) when they are used with subjects, objects,\noblique objects, adverbial adjuncts, with certain lexical, morphological, and\nsemantic features, and co-occurrence restrictions. In addition to the usual\nsense variations due to selectional restrictions on verbal arguments, in most\ncases, the meaning conveyed by a case frame is idiomatic and not compositional,\nwith subtle constraints. In this paper, we present an approach to building a\nconstraint-based case frame lexicon for use in natural language processing in\nTurkish, whose prototype we have implemented under the TFS system developed at\nUniv. of Stuttgart.\n A number of observations that we have made on Turkish have indicated that we\nneed something beyond the traditional transitive and intransitive distinction,\nand utilize a framework where verb valence is considered as the obligatory\nco-existence of an arbitrary subset of possible arguments along with the\nobligatory exclusion of certain others, relative to a verb sense. Additional\nmorphological lexical and semantic constraints on the syntactic constituents\norganized as a 5-tier constraint hierarchy, are utilized to map a given\nsyntactic structure case-fraame to a specific verb sense.",
    "actual_venue": "International Conference On Computational Linguistics"
  },
  {
    "abstract": "Organizations often change their business processes. These changes lead to adjustments in the business process support (BPS) system. The impact of a change in a business process may extend beyond the specific point that has been changed, affecting pre-conditions required for other activities, outputs to be created, or requiring new inputs. This paper introduces a concept of a scope of a change, whose identification facilitates focused efforts when adjusting the BPS system to changes in business processes.",
    "actual_venue": "Caise Workshops"
  },
  {
    "abstract": "Research has been conducted to determine how distributed computations can be mapped to multiprocessors to minimize execution time. The approach described here, known as post-game analysis, incrementally changes the program partitioning in between program execution time in subsequent runs. Post-game analysis differs from conventional iterative refinement or controlled opportunistic perturbation in that no abstract program models or any single objective function are employed to determine the relative merits of two alternative mappings. Multiple optimization subgoals are formulated, based on actual timing data gathered during program execution. Heuristics, based on various optimization subgoals, are then applied to propose changes to the current mapping. Finally, a mapping generation process which prioritizes and resolves conflicting proposals is applied. Results obtained from simulations show that post-game analysis consistently out-performs random placement, load-balancing, and clustering algorithms by 15%. Few iterations are required for simulations involving more than 200 processes and 64 sites. A rule-based architecture enables incremental strategy refinement, thus making post-game analysis easily tailorable to programs written in many concurrent programming paradigms and multiprocessor architectures.",
    "actual_venue": "Ieee Trans Knowl Data Eng"
  },
  {
    "abstract": "One of the main issues with data sharing in cloud environment is to manage user access and its auto revocation in a controlled and flexible way. The issue becomes more complex when privacy on user access has to be ensured as well to hide additional leakage of information. For automatic revocation over cloud data, access can be bounded within certain anticipated time limit so that the access expires beyond effective time period. This time-oriented approach is more rigid and not a one-size-fits-all solution. In certain circumstances, exact time anticipation is not an easy choice. Instead, the alternate solution could be task oriented to restrict user beyond certain number of permissible attempts to access the data. We have proposed oblivious user management (OUM) in which a user can have access on cloud data for certain number of attempts without imposing any time restriction. For user authorization and her subsequent revocation, owner will perform one time setup activity and that is same for all users. The model also alleviates the burden of managing different access parameters at user end with each request as she will always use the same parameter for all valid attempts. Our approach also conceals the privacy of user attempts throughout the communication. Hiding this information helps to avoid distinguishing importance of particular user that has more authorization over others. Evaluation results have proved that OUM hides $$(N-1)$$(N-1) number of permissible attempts until $$N\\mathrm{th}$$Nth request arrives at Cloud Storage. The Performance analysis conducted on Google App Engine revealed that the cost of operations performed in OUM is within the range of 0.097---0.278 $ per 1,000 requests.",
    "actual_venue": "The Journal Of Supercomputing"
  },
  {
    "abstract": "The exponential growth of modern information systems has introduced several new challenges in the management of security requirements. Nowadays, the technological scenario has evolved and the introduction of MAC models provides a better isolation among software components and reduces the damages that the malicious or defective ones can cause to the systems. On one hand it is important to confine applications and limit the privileges that they can request. On the other hand we want to let applications benefit from the flexibility given by MAC models, such as SELinux. In this paper we show how the constructs already available in SELinux and the specialization of security domains can be leveraged to define boundaries where the applications are confined but still able to introduce sophisticated security patterns, such as application isolation and the least privilege principle. After defining the proposed model, we describe how it can be integrated into real systems through the use of examples on Android and Apache Web Server.",
    "actual_venue": "Safeconfig@Ccs"
  },
  {
    "abstract": "This paper studies the on-chip realisation of a dynamic model proposed to simulate crowd behaviour, originated from electrostatic-induced potential fields. It is based on cellular automata (CA), thus taking advantage of their inherent ability to represent sufficiently phenomena of arbitrary complexity and, additionally, to be simulated precisely by digital computers. The model combines electrostatic-induced potential fields to incorporate flexibility in the movement of pedestrians. It primarily calculates distances in an obstacle filled space based on the Euclidean metric. Furthermore, it adopts a computationally fast and efficient method to overcome trouble-inducing obstacles by shifting the moving mechanism to a potential field method based on Manhattan-distance. The hardware implementation of the model is based on FPGA logic. Initialisation of the dedicated processor takes place in collaboration with a detecting and tracking algorithm supported by cameras. The instant response of the processor provides the location of pedestrians around exits. Hardware implementation exploits the prominent feature of parallelism that CA structures inherently possess in contrast to the serial computers, thus accelerating the response of the model. Furthermore, FPGA implementation of the model is advantageous in terms of low-cost, high-speed, compactness and portability features. Finally, the processor could be used as a part of an embedded, real-time, decision support system, aiming at the efficient guidance of crowd in cases of mass egress.",
    "actual_venue": "Microprocessors And Microsystems - Embedded Hardware Design"
  },
  {
    "abstract": "In this paper we will present an algorithm that is capable of recognizing symmetry in an electronic network graph in better than O((n+b)2) time for typical circuits. Applications in symbolic analysis and behavioural modeling are presented",
    "actual_venue": "Circuits And Systems, Iscas , Ieee International Symposium"
  },
  {
    "abstract": "An incomplete self-orthogonal latin square of order v with an empty subarray of order n, an ISOLS(v,n) can exist only if v greater-than-or-equal-to 3n + 1. We show that an ISOLS(6m + 6, 2m) exists for all values of m and thus only the existence of an ISOLS(6m + 2, 2m), m greater-than-or-equal-to 2, remains in doubt.",
    "actual_venue": "Discrete Mathematics"
  },
  {
    "abstract": "Contents typed via keyboards prove to be vulnerable to attacks based on acoustic emanations analysis. However, previous works achieve the attacks under controlled environment, e.g., neglecting the noises or requiring the keyboard to be located in fixed locations. In this study, we present a localization-free online keystroke tracking system (LOL), which enables people to use prior knowledge obtained from the keyboard in one location to recognize real-time keystrokes of the same type of keyboard in any other places, despite various background noises. Combined with support vector machine, we design an detection model to separate keystroke signals from noises. By analyzing the properties of acoustics transmission, we propose an angle-based sampling method with a single microphone to decrease the dependence on certain locations, and it also increases the diversity of signals in the meantime. Our real-world experiments demonstrate a 99.47% keystroke detection rate, a 97.27% recognition accuracy under ideal condition, and an 84.55% content recovery accuracy despite changing locations of the keyboard. Most commercial off-the-shelf sound recording devices, e.g., smartphones, can be used in our system to record acoustic emanations from keystrokes. LOL could attract more community to study security of keyboard devices and promote users to enhance privacy protection awareness.",
    "actual_venue": "Soft Computing"
  },
  {
    "abstract": "Multiple dispatching rule combination method is applied widely to solve multiple objective scheduling problem in practice for its simplicity. It mostly combines particular dispatching rules with linear manner corresponding to multiple scheduling objectives. However, the effectiveness of this method has limited practical value for several reasons. It takes considerable effort to find the optimal weights of dispatching rules, and there is not guarantee these weights would be the right ones for a new problem with its updated system parameters. In this paper, a new heuristic method based on unified ranking measure of the job priority is proposed to deal multiple objective scheduling problem. The priority of jobs regarding to respective dispatching rules are calculated and the unified priority of the job priority is calculated by using analytic hierarchical process with adjusted weights corresponding to scheduling objectives. The simulation result demonstrates that the proposed heuristics is feasible and flexible method to solve multiple objective scheduling problem. The sensitivity analysis indicates how throughput and job weight impact on system effectiveness.",
    "actual_venue": "Lecture Notes In Engineering And Computer Science"
  },
  {
    "abstract": "This report provides a formal definition of large portions of the ECMA/ANSI proposed Standard PL/I language. The metalanguage used is described in the style of the \"Mathematical Semantics\". That is, the definition of PL/I is given by generating a function from a source program. A commentary is also provided to cover the less clear parts of the chosen model. For the convenience of the reader who wishes to have the commentary side by side with the formulae, the report is divided into two parts: Part I contains the description of the notation, the commentary and a cross-reference; Part II contains all the formulae.",
    "actual_venue": "Programming Languages And Their Definition"
  },
  {
    "abstract": "In Long Term Evolution (LTE) networks, two operators might deploy their networks based on frequency division multiplexing (FDD) and time division multiplexing (TDD) in the same geographical area utilizing adjacent frequency bands. In this kind of an environment, the mutual interference, also called adjacent channel interference (ACI), caused by the coexisting adjacent channels of those networks will result in capacity degradation in both systems. In this paper, we investigate the coexistence problem between two macrocells in LTE networks and propose a power allocation-based solution comprising two methods for the base station (BS)-to-BS ACI scenario. Compared to the guard band (GB)-based solution, the proposed methods offer higher spectrum efficiency and even better performance when the GB is equal to or narrower than 10 MHz.",
    "actual_venue": "Vtc Spring"
  },
  {
    "abstract": "Peer-to-peer networks are very popular but the problem of bootstrapping them has largely been ignored. In a fully decentralized environment such as a mobile ad hoc network (MANET) the usual bootstrapping solutions, which typically require a centralized service, are not possible. We present a method of bootstrapping P2P overlay networks running on MANETs which involves multicasting P2P overlay join queries and responses, and caching results at all nodes. Node choose which overlay members to join to based on a utility function that considers both the distance in hops and the overlay neighbors' available energy. Simulation results show that the P2P overlay can closely reflect the underlying top.ology, which reduces energy consumption, that caching the join requests reduces the number of messages required to join the overlay, and that compared to Random Address Probing, there is less overhead and significantly less delay.",
    "actual_venue": "New Orleans, La"
  },
  {
    "abstract": "Instance-intensive workflow applications are widely used in the areas of electronic commerce, advanced manufacture, etc. However, existing studies normally do not consider the problem of reducing their energy consumption by utilizing the advantages of batch processing strategy and the characters of instance-intensive workflow applications. This paper presents an Energy-efficient Instance-intensive Cloud workflows scheduling method with Batch processing, named EICB. Technically, the method is promoted with strategies to merge several activity instances and balance resource utilization of physical machines (PMs) to improve energy efficiency for instance-intensive cloud workflows. The effectiveness and efficiency of the proposed method are validated by extensive experiments.",
    "actual_venue": "Ieee Intl Conf On Parallel And Distributed Processing With Applications, Ubiquitous Computing And Communications, Big Data And Cloud Computing, Social Computing And Networking, Sustainable Computing And Communications (Ispa/Iucc/Bdcloud/Socialcom/Sustaincom"
  },
  {
    "abstract": "We consider the problem of designing an adaptive receiver with an -bit memory for binary orthogonal signaling over a slowly fading Rayleigh channel. Both the cases of decision-feedback and no decision-feedback are considered. We present a problem formulation by defining the contents of the receiver's memory. The structure of the Bayes receiver that makes optimum use of the memory information is then established. The LRT that defines the receiver is obtained explicitly, and it dictates a detector-estimator receiver structure. The detector can be interpreted as being partially coherent, with coherence being achieved asymptotically in the limit of perfect estimation of the fading process. Simulation results are given to show the improved error rate performance of the adaptive receiver. Our results also indicate that decision-feedback should be employed in a manner dependent on the SNR.",
    "actual_venue": "Communications, IEEE Transactions  "
  },
  {
    "abstract": "State-of-the-art item recommendation algorithms, which apply Factorization Machines (FM) as a scoring function and pairwise ranking loss as a trainer (PRFM for short), have been recently investigated for the implicit feedback based context-aware recommendation problem (IFCAR). However, good recommenders particularly emphasize on the accuracy near the top of the ranked list, and typical pairwise loss functions might not match well with such a requirement. In this paper, we demonstrate, both theoretically and empirically, PRFM models usually lead to non-optimal item recommendation results due to such mismatch. Inspired by the success of LambdaRank, we introduce Lambda Factorization Machines (LambdaFM), which is particularly intended for optimizing ranking performance for IFCAR. We also point out that the original lambda function suffers from the issue of expensive computational complexity in such settings due to a large amount of unobserved feedback. Hence, instead of directly adopting the original lambda strategy, we create three effective lambda surrogates  by conducting a theoretical analysis for lambda from the top-N optimization perspective.\nFurther, we prove that the proposed lambda surrogates are generic and applicable to a large set of pairwise ranking loss functions. Experimental results demonstrate LambdaFM significantly outperforms state-of-the-art algorithms on three real-world datasets in terms of four standard ranking measures.",
    "actual_venue": "Acm International Conference On Information And Knowledge Management"
  },
  {
    "abstract": "In this paper we study the following problem: how to divide a cake among the children attending a birthday party such that all the children get the same amount of cake and the same amount of icing. This leads us to the study of the following. A perfect k-partitioning of a convex set S is a partitioning of S into k convex pieces such that each piece has the same area and 1 k of the perimeter of S. We show that for any k, any convex set admits a perfect k-partitioning. Perfect partitionings with additional constraints are also studied.",
    "actual_venue": "Jcdcg"
  },
  {
    "abstract": "Recall of new information is the basis for reading comprehension and is a fundamental skill that affects virtually every area of human activity in which information is displayed. Because the computer has become the primary means by which information is disseminated, Human-Computer Interaction (HCI) factors play an important role in the effectiveness of the process. This paper describes the results of an experiment conducted to study the effect of color and repetition on the comprehension of information displayed by way of a computer monitor.",
    "actual_venue": "Acm Southeast Regional Conference"
  },
  {
    "abstract": "Within the Content Based Image Retrieval (CBIR) framework, one of the main challenges is to tackle the scalability issues. We propose a new compact signature for similarity search. We use an original method to perform a high compression of signatures while retraining their effectiveness. We propose an embedding method that maps large signatures into a low-dimensional Hilbert space. We evaluated the method on Holidays database and compared the results with methods of state-of-the-art.",
    "actual_venue": "Image Processing"
  },
  {
    "abstract": "•Successful breast lesion registration between 3D x-ray and ultrasound images.•Relating corresponding masses across modalities can improve characterization.•Deformable registration found to show significant improvement (p ≤ 0.05) in comparison to rigid registration.•Skin markers can be used to improve deformable registration results.",
    "actual_venue": "Medical Image Analysis"
  },
  {
    "abstract": "While many methods like multidimensional scaling (MDS) are exploited to represent and visualize symmetric distance matrices on 2-dimensional spaces, asymmetric proximity matrices such as an importing/exporting matrix from/to countries cannot be perfectly represented on metric spaces, since the methods assume a symmetric distance matrix. To overcome such an intrinsic limitation, in this paper, we propose a dynamic learning for metric representations of asymmetric proximity data to better understand the data. The proposed learning generates two representations (maps) with the column vectors (importing) and row vectors (exporting) of the matrix, respectively. To better present the patterns, we supplement the maps with two analysis tools: cluster analysis and flow analysis, which connect and compare the different patterns from the different maps. Experimental results using cola-brand-switching data and world-trade data confirm that the proposed learning method is useful to understand asymmetric proximity data.",
    "actual_venue": "SMC"
  },
  {
    "abstract": "Cyber-Physical Systems (CPS) have gained wide popularity, however, developing and debugging CPS remain significant challenges. Many bugs are detectable only at runtime under deployment conditions that may be unpredictable or at least unexpected at development time. The current state of the practice of debugging CPS is generally ad hoc, involving trial and error in a real deployment. For increased rigor, it is appealing to bring formal methods to CPS verification. However developers often eschew formal approaches due to complexity and lack of efficiency. This paper presents Brace Assertion, a specification framework based on natural language queries that are automatically converted to a determinitic class of timed automata used for runtime monitoring. To reduce runtime overhead and support properties that reference predicate logic, we use a second monitor automaton to create filtered traces on which to run the analysis using the specification monitor. We evaluate the Brace Assertion framework using a real CPS case study and show that the framework is able to minimize runtime overhead with an increasing number of monitors.",
    "actual_venue": "Ieee International Conference On Mobile Ad Hoc And Sensor Systems"
  },
  {
    "abstract": "Our objective was to determine the prevalence of the term preembryo in the scientific literature using a bibliometric study in the Web of Science database. We retrieved data from the Web of Science from 1986 to 2005, covering a range of 20 years since the term was first published. Searches for the terms embryo, blastocyst, preimplantation embryo, and preembryo were performed. Then, Boolean operators were applied to measure associations between terms. Finally, statistical assessments were made to compare the use of each term in the scientific literature, and in specific areas where preembryo is most used. From a total of 93,019 registers, 90,888 corresponded to embryo; 8,366 to blastocyst; 2,397 to preimplantation embryo; and 172 to preembryo. The use frequency for preembryo was 2:1000. The term preembryo showed a lower cumulative impact factor (343) in comparison with the others (25,448; 5,530; and 546; respectively) in the highest scored journal category. We conclude that the term preembryo is not used in the scientific community, probably because it is confusing or inadequate. The authors suggest that its use in the scientific literature should be avoided in future publications. The bibliometric analysis confirms this statement. While preembryo hardly ever is used, terms such as preimplantation embryo and blastocyst have gained wide acceptance in publications from the same areas of study. © 2011 Wiley Periodicals, Inc.",
    "actual_venue": "Jasist"
  },
  {
    "abstract": "Proper names of organisations are a special case of collective nouns. Their meaning can be conceptualised as a collective unit or as a plurality of persons, permitting different morphological marking of anaphoric pronouns. This paper explores the variability of references to organisation names with 1) a corpus analysis and 2) two crowd-sourced story continuation experiments. The first shows the bias for singular vs. plural conceptualisation depends on the level of formality of a text. In the second, we observe a strong preference for plural they typical of informal speech. This preference is reduced for edited corpus data compared with constructed sentences.",
    "actual_venue": "Named Entities"
  },
  {
    "abstract": "Recently, there has been focus on determining the conditions under which the data processing inequality for quantum relative entropy is satisfied with approximate equality. The solution of the exact equality case is due to Petz, who showed that the quantum relative entropy between two quantum states stays the same after the action of a quantum channel if and only if there is a reversal channel that recovers the original states after the channel acts. Furthermore, this reversal channel can be constructed explicitly and is now called the Petz recovery map. Recent developments have shown that a variation of the Petz recovery map works well for recovery in the case of approximate equality of the data processing inequality. Our main contribution here is a proof that bosonic Gaussian states and channels possess a particular closure property, namely, that the Petz recovery map associated to a bosonic Gaussian state sigma and a bosonic Gaussian channel N is itself a bosonic Gaussian channel. We furthermore give an explicit construction of the Petz recovery map in this case, in terms of the mean vector and covariance matrix of the state s and the Gaussian specification of the channel N.",
    "actual_venue": "Journal Of Physics A-Mathematical And Theoretical"
  },
  {
    "abstract": "Variable annuities are very appealing to the investor. For example, in United States, sales volume on variable annuities grew to a record 184 billion in calendar year 2006. However, due to their complicated payoff structure, their valuation and risk management are challenges to the insurers. In this paper, we study a variable annuity contract with cliquet options in Asia markets. The contact has quanto feature. We propose an efficient Monte Carlo method to value the contract. Numerical examples suggest our approach is quite efficient.",
    "actual_venue": "Winter Simulation Conference"
  },
  {
    "abstract": "Most medical decision problems are exceedingly complex and contain a large number of variables. Abstraction facilitates the process of building a decision model by allowing a model builder to work at a level of detail that he is most comfortable with; it is also useful in time-critical situations or when there is insufficient data to support complete specification of probabilities of the uncertain events. In this paper we identify and formalize abstraction and refinement operations commonly used in model construction. We illustrate the use of these mechanisms with an example on the follow-up management of colorectal cancer patients after surgery.",
    "actual_venue": "Journal Of The American Medical Informatics Association"
  },
  {
    "abstract": "Recent studies have reported the computed radiography (CR) dose creep problem and therefore the need to have monitoring processes in place in clinical departments. The objective of this study is to provide a better technological solution to implement a regular CR dose monitoring process. An online automatic CR dose data mining program which can be applied to different systems was developed based on freeware and existing softwares in the Picture Archiving and Communication System (PACS) server. The program was tested with 69 CR images. This preliminary study shows that the program addresses the major weaknesses of some existing studies including involvement of manual procedures in the monitoring process and being only applicable to a single manufacturer's CR images. The proposed method provides an efficient and effective solution to implement a CR dose monitoring program regularly in busy clinical departments to regulate the dose creep problem so as to reinforce the 'As Low As Reasonably Achievable' (ALARA) principle.",
    "actual_venue": "Computer Methods And Programs In Biomedicine"
  },
  {
    "abstract": "In recent years, the biological literature has seen a significant increase of reported methods for identifying both structure and parameters of ordinary differential equations (ODEs) from time series data. A natural way to evaluate the performance of such methods is to try them on a sufficient number of realistic test cases. However, weak practices in specifying identification problems and lack of commonly accepted benchmark problems makes it difficult to evaluate and compare different methods.To enable better evaluation and comparisons between different methods, we propose how to specify identification problems as optimization problems with a model space of allowed reactions (e.g. reaction kinetics like Michaelis-Menten or S-systems), ranges for the parameters, time series data and an error function. We also define a file format for such problems. We then present a collection of more than 40 benchmark problems for ODE model identification of cellular systems. The collection includes realistic problems of different levels of difficulty w.r.t. size and quality of data. We consider both problems with simulated data from known systems, and problems with real data. Finally, we present results based on our identification algorithm for all benchmark problems. In comparison with publications on which we have based some of the benchmark problems, our approach allows all problems to be solved without the use of supercomputing.The benchmark problems are available at www.odeidentification.org.Supplementary data are available at Bioinformatics online.",
    "actual_venue": "Bioinformatics"
  },
  {
    "abstract": "AbstractThis paper aims to use semantic database for recommendation purposes. It deals with two very specific problems of Recommendation System, namely Cold Start user and Diversity. We first describe cold start users and predict recommendation for them using information theory based methods. To introduce serendipitous results we also include aggregate diversity methods to the predicted ratings. Furthermore, we explain the results obtained from the rated items, and also increase the Intra List Diversity using a ranking-based approach that is different from the popularity-based approach employed in the past.",
    "actual_venue": "Periodicals"
  },
  {
    "abstract": "Weakest precondition based method for specification and verification of geographically distributed system is described. For this purpose spatial predicates have been defined. A distributed mutual exclusion algorithm is proposed and is used to illustrate this verification tool.",
    "actual_venue": "Acm Sigsoft Software Engineering Notes"
  },
  {
    "abstract": "Objective: Electronic health record (EHR) data are used to exchange information among health care providers. For this purpose, the quality of the data is essential. We developed a data quality feedback tool that evaluates differences in EHR data quality among practices and software packages as part of a larger intervention. Methods: The tool was applied in 92 practices in the Netherlands using different software packages. Practices received data quality feedback in 2010 and 2012. Results: We observed large differences in the quality of recording. For example, the percentage of episodes of care that had a meaningful diagnostic code ranged from 30% to 100%. Differences were highly related to the software package. A year after the first measurement, the quality of recording had improved significantly and differences decreased, with 67% of the physicians indicating that they had actively changed their recording habits based on the results of the first measurement. About 80% found the feedback helpful in pinpointing recording problems. One of the software vendors made changes in functionality as a result of the feedback. Conclusions: Our EHR data quality feedback tool is capable of highlighting differences among practices and software packages. As such, it also stimulates improvements. As substantial variability in recording is related to the software package, our study strengthens the evidence that data quality can be improved substantially by standardizing the functionalities of EHR software packages.",
    "actual_venue": "Journal Of The American Medical Informatics Association"
  },
  {
    "abstract": "Technology plays an important role on the regional competitiveness. In this paper, we built a regional technology diffusion model based on MABS considering agents similar to irregular Cellular Automata model. The results show that under the impact of heterogeneous traffic lines, the traditional center-hinterland diffusion mode has been no longer fit. In reality technology diffusion mode complies with a hub-net structure. Traffic condition plays an important role in regional technology improvement. A preferential tax policy can be conductive to the improvement of the local technology level.",
    "actual_venue": "Cellular Automata, Acri"
  },
  {
    "abstract": "This letter introduces a new fairness concept, namely proportional quasi-fairness and proves that the optimal end-to-end rate of a network utility maximization can be proportionally quasi-fair with a properly chosen network utility function for an arbitrary compact feasible set.",
    "actual_venue": "Ieice Transactions On Fundamentals Of Electronics Communications And Computer Sciences"
  },
  {
    "abstract": "The increasing incidence of hospital acquired infections caused by antibiotic resistant pathogens has led to an increase in morbidity and mortality, finding alternative antibiotics unaffected by resistance mechanisms is fundamentally important for treating this problem. Naturally occurring proteins usually carry short peptide fragments that exhibit noticeable biological activity against a wide variety of microorganisms such as bacteria, fungi and protozoa. Traditional discovery of such antimicrobially active fragments (i.e. antimicrobial peptides, AMPs) from protein repertoire is either random or led by chance. Here, we report the use of a rational protocol that combines in silico prediction and in vitro assay to identify potential AMPs with high activity and low toxicity from the entire human genome. In the procedure, a three-step inference strategy is first proposed to perform genome-wide analysis to infer AMPs in a high-throughput manner. By employing this strategy we are able to screen more than one million peptide candidates generated from various human proteins, from which we identify four highly promising samples, and subsequently their antibacterial activity on five strains as well as cytotoxicity on human myoblasts are tested experimentally. As a consequence, two high-activity, low-toxicity peptides are discovered, which could be used as the structural basis to further develop new antibiotics. In addition, from 1491 known AMPs we also derive a quantitative measure called antibacterial propensity index (API) for 20 naturally occurring amino acids, which shows a significant allometric correlation with the theoretical minimal inhibitory concentration of putative peptides against Gram-positive and Gram-negative bacteria. This study may provide a proof-of-concept paradigm for the genome-wide discovery of novel antimicrobial peptides by using a combination of in silico and in vitro analyses.",
    "actual_venue": "Biosystems"
  },
  {
    "abstract": "AbstractCatering Service Supply Chain CSSC is a new supply chain of which Catering Service Integrator CSI is the core enterprise. The main purpose of CSSC is to provide supply chain services for different catering enterprises and restaurants. Instability, non-standardisation characteristics of the Chinese catering industry, the specialty and diversity of different restaurants lead to demand uncertainty of CSSC. This research classifies various uncertainty scenarios based on supply-driven theory. Supply-driven methodology is used to induce uncertainty sources to the supply-side, which can be controlled by CSI. Two strategies, service coordination with wide knowledge sharing and synchronous decision with intelligent inducement, are designed to induce and integrate customer demand to get the scale effect and to balance the personal demand. Correspondingly, this research presents the technology solutions, including supply-driven coordinative process, coordinative integration service platform and intelligent matching system, with the related information systems integration framework and data/knowledge integration natures.",
    "actual_venue": "Periodicals"
  },
  {
    "abstract": "We address the problem of prediction of data that is vertically partitioned, that is where local sites hold some of the attributes of all of the records. This situation is natural when data is collected by channels that are physically separated. For distributed prediction, we show that a technique called attribute ensembles is simple, predicts almost as well as a centralized predictor, reduces the amount of communication required, distributes computation and data access well, and allows each local site to keep its raw data private. We show how to extend attribute ensembles to data that is partitioned both horizontally and vertically.",
    "actual_venue": "J Parallel Distrib Comput"
  },
  {
    "abstract": "This paper describes the embedded block coding algorithm at the heart of the JPEG 2000 image compression standard. The paper discusses key considerations which led to the development and adoption of this algorithm, and also investigates performance and complexity issues. The JPEG 2000 coding system achieves excellent compression performance, somewhat higher (and, in some cases, substantially higher) than that of SPIHT with arithmetic coding, a popular benchmark for comparison The algorithm utilizes the same low complexity binary arithmetic coding engine as JBIG2. Together with careful design of the bit-plane coding primitives, this enables comparable execution speed to that observed with the simpler variant of SPIHT without arithmetic coding. The coder offers additional advantages including memory locality, spatial random access and ease of geometric manipulation.",
    "actual_venue": "Signal Processing: Image Communication"
  },
  {
    "abstract": "This paper focuses on the problems encountered in the actual data processing with the use of the existing aerial target localization methods, analyzes the causes of the problems, and proposes an improved algorithm. Through the processing of the sea experiment data, it is found that the existing algorithms have higher requirements for the accuracy of the angle estimation. The improved algorithm reduces the requirements of the angle estimation accuracy and obtains the robust estimation results. The closest distance matching estimation algorithm and the horizontal distance estimation compensation algorithm are proposed. The smoothing effect of the data after being post-processed by using the forward and backward two-direction double-filtering method has been improved, thus the initial stage data can be filtered, so that the filtering results retain more useful information. In this paper, the aerial target height measurement methods are studied, the estimation results of the aerial target are given, so as to realize the three-dimensional localization of the aerial target and increase the understanding of the underwater platform to the aerial target, so that the underwater platform has better mobility and concealment.",
    "actual_venue": "Sensors"
  },
  {
    "abstract": "The bystander effect is a well-known phenomenon in criminology, stating that bystanders tend to inhibit people's tendency to intervene in situations where norms are violated. This paper presents an agent-based simulation model of this phenomenon. The simulation model presented demonstrates the decision process of an agent for norm violation situations with different characteristics, such as high versus low personal implications. The model has been tested by performing a number of case studies. The outcome of these case studies show that the model is able to represent the behaviour of bystanders as expected based on various experimental studies.",
    "actual_venue": "Lecture Notes In Computer Science"
  },
  {
    "abstract": "Continuous advances in computer technology are making it possible to construct virtual environments with an ever-increasing sense of visual realism. What is lacking are interfaces that allow users to manipulate virtual objects in an intuitive manner. In this paper, we present a 7 DOF tension-based haptic interface that allows users to not only grip an object but also to sense an object's width. We have developed a system to utilize the physical action of gripping to display grasp manipulation in virtual environments. We also present a method to calculate the position and display force associated with this gripping mechanism. Finally, we show the validity of our proposed haptic interface through examples.",
    "actual_venue": "Vrst"
  },
  {
    "abstract": "programs whose implementation is supported by the automatic,library-based synthesis of linear compositions of modules. More complex controlstructures glueing the linear portions together must be programmed byhand. Still, being able to synthesize linear program fragments drastically improvesover other methods where only single components can be retrieved fromthe underlying repository. This is already true in cases where one is only interestedin the functionality of single components,...",
    "actual_venue": "CAV"
  },
  {
    "abstract": "In a cooperative cognitive radio (CR) network when a group of CR users acts as relays for a given CR user, a cooperative beamforming can be used to improve the quality of communications. However, this cooperative beamforming can introduce asynchronous interference at the primary receiver due to different propagation delays between different CR relays and the primary receiver. In this paper, we propose an innovative cooperative beamforming method that maximizes the received signal power at the secondary destination while keeping the asynchronous interference at the primary receiver below a target threshold. The presented numerical results show that the proposed beamforming method can significantly reduce the interference at the primary receiver and thereby decreases the outage probability up to 75% compared to the zero forcing beamforming method, for a primary user's busy probability of 0.75. This beamforming method is further extended for the case when the channels between the primary receiver and the CR relays are not known perfectly.",
    "actual_venue": "Ieee International Conference On Communications"
  },
  {
    "abstract": "We explore, in this paper, the behavior of the mammalians retina considered as an analog-to-digital converter for the incoming light stimuli. This work extends our previous effort towards combining results in neurosciences with image processing techniques. We base our study on a biologically realistic model that reproduces the neural code as generated by the retina. The neural code, that we consider here, consists of non-deterministic temporal sequences of uniformly shaped electrical impulses, also termed as spikes. We describe, starting from this spike-based code, a dynamic quantization scheme that relies on the so-called rate coding hypothesis. We, then, propose a possible decoding procedure. This yields an original coding/decoding system which evolves dynamically from coarse to fine, and from uniform to non-uniform. Furthermore, we emit a possible interpretation for the non-determinism observed in the spike timings. In order to do this, we implement a three-staged processing system mapping the anatomical architecture of the retina. We, then, model the retinal noise by a dither signal which permits us to define the retina behavior as a non-subtractive dithered quantizer. The coding/decoding system, that we propose, offers several interesting features as time scalability as well as reconstruction error whitening and de-correlation from the input stimuli.",
    "actual_venue": "Image Analysis For Multimedia Interactive Services"
  },
  {
    "abstract": "A model for the liquid/vapor phase transitions in a shock tube is studied. Mathematical analysis for the one-dimensional isothermal case is carried out. A sufficient condition for the existence of traveling waves is given. These traveling waves represent liquefaction and evaporation shocks. The nonexistence of some of these traveling waves when the shock speed is smaller than some number is proved. Major one-dimensional wave patterns observed in actual experiments with retrograde fluids are also observed in solutions of Riemann problems. A rough estimate of the difference of the calculated pressure in the solution of the Riemann problem and that in experimental data due to the modeling is given.",
    "actual_venue": "Siam Journal On Applied Mathematics"
  }
]